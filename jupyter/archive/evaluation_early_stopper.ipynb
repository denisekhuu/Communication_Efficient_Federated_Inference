{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33165d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random \n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)                # CPU\n",
    "    torch.cuda.manual_seed(seed)           # Current GPU\n",
    "    torch.cuda.manual_seed_all(seed)       # All GPUs\n",
    "    np.random.seed(seed)                   # NumPy\n",
    "    random.seed(seed)                      # Python random\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "32 * 7 *7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from federated_inference.common.environment import DataSetEnum\n",
    "\n",
    "class DataConfiguration():\n",
    "    \n",
    "    #MNIST_FASHION_DATASET Configurations\n",
    "    FMNIST_NAME = 'FMNIST'\n",
    "    FMNIST_DATASET_PATH = os.path.join('./data/fmnist')\n",
    "    FMNIST_LABELS = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker',  'Bag', 'Ankle Boot']\n",
    "    \n",
    "    #MNIST_DATASET Configurations\n",
    "    MNIST_NAME = 'MNIST'\n",
    "    MNIST_DATASET_PATH = os.path.join('./data/mnist')\n",
    "    \n",
    "    #CIFAR_DATASET Configurations\n",
    "    CIFAR10_NAME = 'CIFAR10'\n",
    "    CIFAR10_DATASET_PATH = os.path.join('./data/cifar10')\n",
    "    CIFAR10_LABELS = ['Plane', 'Car', 'Bird', 'Cat','Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "\n",
    "    def __init__(self, dataset_name : str = None):\n",
    "        load_dotenv(override=True)\n",
    "        self.DATASET_NAME = dataset_name if dataset_name else os.getenv('DATASET_NAME', 'MNIST')\n",
    "        if self.DATASET_NAME == DataSetEnum.MNIST.value: \n",
    "            self.INSTANCE_SIZE = (1, 28, 28)\n",
    "            self.DATASET = DataSetEnum.MNIST\n",
    "            self.DATASET_PATH = os.path.join(os.getenv('DATASET_PATH', self.MNIST_DATASET_PATH))\n",
    "            self.LABELS = range(10)\n",
    "        if self.DATASET_NAME == DataSetEnum.FMNIST.value: \n",
    "            self.INSTANCE_SIZE = (1, 28, 28)\n",
    "            self.DATASET = DataSetEnum.FMNIST\n",
    "            self.DATASET_PATH = os.path.join(os.getenv('DATASET_PATH', self.FMNIST_DATASET_PATH))\n",
    "            self.LABELS = self.FMNIST_LABELS\n",
    "        if self.DATASET_NAME == DataSetEnum.CIFAR10.value:\n",
    "            self.INSTANCE_SIZE = (1, 32, 32)\n",
    "            self.DATASET = DataSetEnum.CIFAR10\n",
    "            self.DATASET_PATH = os.path.join(os.getenv('DATASET_PATH', self.CIFAR10_DATASET_PATH))\n",
    "            self.LABELS =  self.CIFAR10_LABELS\n",
    "\n",
    "    def __dict__(self):\n",
    "        return {\n",
    "            \"dataset_name\": self.DATASET_NAME, \n",
    "            \"labels\": list(self.LABELS),\n",
    "            \"size\": self.INSTANCE_SIZE\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1618c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class HybridSplitModelConfiguration():\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                          else \"mps\" if torch.backends.mps.is_available()\n",
    "                          else \"cpu\")\n",
    "\n",
    "    def __init__(self,  \n",
    "        server_model: nn.Module, \n",
    "        client_base_model: nn.Module, \n",
    "        client_classifier_head: nn.Module, \n",
    "        client_ig_head: nn.Module,          \n",
    "        learning_rate: float = 0.001, \n",
    "        batch_size_train: int = 64, \n",
    "        batch_size_val: int = 64, \n",
    "        batch_size_test: int = 64, \n",
    "        train_shuffle: bool = True, \n",
    "        val_shuffle: bool = False, \n",
    "        test_suffle: bool = False, \n",
    "        n_epochs: int = 60,\n",
    "        train_ratio: float = 0.8):\n",
    "        self.SERVER_MODEL = server_model\n",
    "        self.CLIENT_BASE_MODEL = client_base_model\n",
    "        self.CLIENT_CLASSIFIER_MODEL = client_classifier_head\n",
    "        self.CLIENT_IG_MODEL = client_ig_head\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "        self.TRAIN_RATIO = train_ratio\n",
    "        self.BATCH_SIZE_TRAIN = batch_size_train\n",
    "        self.BATCH_SIZE_VAL = batch_size_val\n",
    "        self.BATCH_SIZE_TEST = batch_size_test\n",
    "        self.TRAIN_SHUFFLE = train_shuffle\n",
    "        self.VAL_SHUFFLE = val_shuffle\n",
    "        self.TEST_SHUFFLE = test_suffle\n",
    "        self.N_EPOCH = n_epochs\n",
    "\n",
    "    def __dict__(self):\n",
    "        return {\n",
    "            \"learning_rate\": self.LEARNING_RATE, \n",
    "            \"train_ratio\": self.TRAIN_RATIO,\n",
    "            \"batch_size_train\": self.BATCH_SIZE_TRAIN,\n",
    "            \"batch_size_val\": self.BATCH_SIZE_VAL,\n",
    "            \"batch_size_test\": self.BATCH_SIZE_TEST, \n",
    "            \"train_shuffle\": self.TRAIN_SHUFFLE,\n",
    "            \"val_shuffle\": self.VAL_SHUFFLE,\n",
    "            \"test_shuffle\": self.TEST_SHUFFLE,\n",
    "            \"n_epoch\": self.N_EPOCH, \n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d9fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformConfiguration(): \n",
    "\n",
    "    def __init__(self, tensor_size = [1,28,28], method_name = 'full', mask_size = [14,14], dimensions = [1,2], stride = 14, n_position = None, drop_p = None):\n",
    "        self.TENSOR_SIZE = tensor_size\n",
    "        self.METHOD_NAME = method_name\n",
    "        self.MASK_SIZE = mask_size \n",
    "        self.DIMENSIONS = dimensions\n",
    "        self.STRIDE = stride\n",
    "        self.N_POSITION = n_position\n",
    "        self.DROP_P = drop_p\n",
    "\n",
    "    def __dict__(self):\n",
    "        return {\n",
    "            \"tensor_size\": self.TENSOR_SIZE, \n",
    "            \"method_name\": self.METHOD_NAME,\n",
    "            \"mask_size\": self.MASK_SIZE,\n",
    "            \"dimensions\": self.DIMENSIONS,\n",
    "            \"stride\": self.STRIDE,\n",
    "            \"n_position\": self.N_POSITION,\n",
    "            \"drop_p\": self.DROP_P,\n",
    "\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class HybridSplitBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return x\n",
    "\n",
    "class LocalHybridSplitClassifierHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1568, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "class RouterHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1568, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "class GlobalHybridSplitCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(6272, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_concat):\n",
    "        return self.classifier(x_concat)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc593679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from federated_inference.common.environment import Member\n",
    "from collections.abc import Iterable\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class HybridSplitClient():\n",
    "\n",
    "    def __init__(self, \n",
    "            idx, \n",
    "            seed: int,\n",
    "            data_config: DataConfiguration,\n",
    "            model_config: HybridSplitModelConfiguration,\n",
    "            dataset: TorchDataset,\n",
    "            labels,\n",
    "            log: bool = True, \n",
    "            log_interval: int = 100, \n",
    "            save_interval: int = 20\n",
    "        ):\n",
    "        self.idx = idx\n",
    "        self.seed = seed\n",
    "        self.data = dataset\n",
    "        self.data_config = data_config\n",
    "        self.model_config = model_config\n",
    "        self.device = model_config.DEVICE\n",
    "        self.labels = labels\n",
    "        self.numerical_labels = range(len(labels))\n",
    "        self.member_type = Member.CLIENT\n",
    "        self.model = None\n",
    "        self.log = log\n",
    "        self.log_interval = log_interval\n",
    "        self.save_interval = save_interval\n",
    "        self.base_model = model_config.CLIENT_BASE_MODEL().to(self.device)\n",
    "        self.classifier_model = model_config.CLIENT_CLASSIFIER_MODEL().to(self.device)\n",
    "        self.router_model = model_config.CLIENT_IG_MODEL().to(self.device)\n",
    "\n",
    "    def select_subset(self, ids: Iterable[int], set_type: str = \"train\"):\n",
    "        if set_type == \"test\":\n",
    "            return Subset(self.data.test_dataset, ids)\n",
    "        else: \n",
    "            return Subset(self.data.train_dataset, ids)\n",
    "\n",
    "    def send_all(self):\n",
    "        return self.data.train_dataset\n",
    "\n",
    "    def request_pred(self, idx: int|None = None, set_type: str = \"test\", pred_all: bool= False, keep_label: bool = False): \n",
    "        if idx != None:\n",
    "            if set_type == \"test\":\n",
    "                return self.data.test_dataset[idx] if keep_label else self.data.test_dataset[idx][0] \n",
    "        elif pred_all:\n",
    "            return self.data.test_dataset if keep_label else [img for img, label in self.data.test_dataset]\n",
    "\n",
    "    def check(self, predicted_labels, pred_all: bool = True):\n",
    "        if pred_all:\n",
    "            true_labels = self.data.test_dataset.targets\n",
    "            accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "            precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "            recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "            f1 = f1_score(true_labels, predicted_labels, average='macro') \n",
    "\n",
    "            print(\"\\n=== Metrics ===\")\n",
    "            print(f\"Accuracy : {accuracy:.4f}\")\n",
    "            print(f\"Precision: {precision:.4f}\")\n",
    "            print(f\"Recall   : {recall:.4f}\")\n",
    "            print(f\"F1 Score : {f1:.4f}\") \n",
    "\n",
    "            cm = confusion_matrix(true_labels, predicted_labels, labels=self.numerical_labels)\n",
    "            self.cm = pd.DataFrame(cm, index=[f'True {l}' for l in self.labels],\n",
    "                                    columns=[f'Pred {l}' for l in self.labels])\n",
    "            self.accuracy = accuracy\n",
    "            self.precision = precision\n",
    "            self.recall = recall\n",
    "            self.f1 = f1 \n",
    "\n",
    "\n",
    "    def load(self):\n",
    "        result_path = f\"./results/hybrid/{self.data_config.DATASET_NAME}/{self.seed}\"\n",
    "        client_result_path = os.path.join(result_path, \"clients\") \n",
    "\n",
    "        # Base\n",
    "        model_path = os.path.join(client_result_path, f'model_client_base_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        network_state_dict = torch.load(model_path)\n",
    "        self.base = self.base_model.load_state_dict(network_state_dict)\n",
    "\n",
    "        # Classifier Head\n",
    "        model_path = os.path.join(client_result_path, f'model_client_classifier_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        network_state_dict = torch.load(model_path)\n",
    "        self.classifier_model.load_state_dict(network_state_dict)\n",
    "\n",
    "        # Router Head\n",
    "        model_path = os.path.join(client_result_path, f'model_client_router_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        network_state_dict = torch.load(model_path)\n",
    "        self.router_model.load_state_dict(network_state_dict)\n",
    "\n",
    "    def to_loader(self, testdata):\n",
    "        self.testloader = DataLoader(self.data.test_dataset, batch_size=self.model_config.BATCH_SIZE_TEST, shuffle=False) \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_inference.common.environment import Member\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "class EarlyStopper():\n",
    "    def __init__(self, patience = 20, min_delta = 0.00001):\n",
    "        self.patience = patience \n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0 \n",
    "        self.best_loss = None \n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None: \n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else: \n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        \n",
    "\n",
    "class HybridSplitServer():\n",
    "\n",
    "    def __init__(self, \n",
    "            idx, \n",
    "            seed,\n",
    "            model_config: HybridSplitModelConfiguration,\n",
    "            data_config: DataConfiguration,\n",
    "            log: bool = True, \n",
    "            log_interval: int = 100,\n",
    "            save_interval: int = 20\n",
    "        ):\n",
    "        self.idx = idx\n",
    "        self.seed = seed\n",
    "        self.model_config = model_config\n",
    "        self.data_config = data_config\n",
    "        self.seed = seed\n",
    "        self.number_of_clients = 4\n",
    "        self.n_epoch = model_config.N_EPOCH\n",
    "        self.device = model_config.DEVICE\n",
    "        self.member_type = Member.SERVER\n",
    "        self.server_model = model_config.SERVER_MODEL().to(self.device)\n",
    "        self.client_base_models = [model_config.CLIENT_BASE_MODEL().to(self.device) for c in range(self.number_of_clients)]\n",
    "        self.client_classifier_models = [model_config.CLIENT_CLASSIFIER_MODEL().to(self.device) for c in range(self.number_of_clients)]\n",
    "        self.client_ig_models = [model_config.CLIENT_IG_MODEL().to(self.device) for c in range(self.number_of_clients)]\n",
    "        self.CRITERION = nn.CrossEntropyLoss()\n",
    "        self.CRITERION_NAME = \"CrossEntropyLoss\"\n",
    "        self.weight_decay = 0\n",
    "        self.SERVER_OPTIMIZER = optim.Adam(self.server_model.parameters() , lr=model_config.LEARNING_RATE, weight_decay=self.weight_decay)\n",
    "        self.CLIENT_BASE_OPTIMIZERS =  [optim.Adam(self.client_base_models[c].parameters() , lr=model_config.LEARNING_RATE, weight_decay=self.weight_decay ) for c in range(self.number_of_clients)]\n",
    "        self.CLIENT_CLASSIFIER_OPTIMIZERS =  [optim.Adam(self.client_classifier_models[c].parameters() , lr=model_config.LEARNING_RATE, weight_decay=self.weight_decay) for c in range(self.number_of_clients)]\n",
    "        self.CLIENT_IG_OPTIMIZERS =  [optim.Adam(self.client_ig_models[c].parameters() , lr=model_config.LEARNING_RATE, weight_decay=self.weight_decay ) for c in range(self.number_of_clients)]\n",
    "        self.OPTIMIZER_NAME = \"Adam\"\n",
    "        self.LOCAL_CLASSIFIER_CRITERION = nn.CrossEntropyLoss()\n",
    "        self.LOCAL_IG_CRITERION = nn.BCELoss()\n",
    "\n",
    "        self.log = log\n",
    "        self.log_interval = log_interval\n",
    "        self.save_interval = save_interval\n",
    "\n",
    "        if self.log: \n",
    "            self.train_losses = []\n",
    "            self.test_losses = []\n",
    "            self.accuracies = []\n",
    "\n",
    "\n",
    "    def _to_loader(self, trainsets, testsets, batch_size_train, batch_size_val, batch_size_test, train_shuffle, val_shuffle, test_shuffle, train_ratio):\n",
    "        # TODO refactoing to use self\n",
    "        if True:\n",
    "            dataset_length = len(trainsets[0])\n",
    "            assert all(len(trainset) == dataset_length for trainset in trainsets), \"All trainsets must be the same length\"\n",
    "\n",
    "            indices = np.arange(dataset_length)\n",
    "            self.train_set_indices = np.arange(dataset_length)\n",
    "\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "            train_end = round(train_ratio * dataset_length)\n",
    "            train_indices = indices[:train_end]\n",
    "            val_indices = indices[train_end:]\n",
    "\n",
    "            traindatas = [Subset(trainset, train_indices) for trainset in trainsets]\n",
    "            valdatas = [Subset(trainset, val_indices) for trainset in trainsets]\n",
    "        else:\n",
    "            traindatas = [Subset(trainset, range(round(train_ratio*len(trainset)))) for trainset in trainsets]\n",
    "            valdatas = [Subset(trainset, range(round(train_ratio*len(trainset)), len(trainset))) for trainset in trainsets]\n",
    "        self.trainloader = [DataLoader(traindata, batch_size=batch_size_train, shuffle=False)  for traindata in traindatas]\n",
    "        self.valloader = [DataLoader(valdata, batch_size=batch_size_val, shuffle=False) for valdata in valdatas]\n",
    "        self.testloader = [DataLoader(testdata, batch_size=batch_size_test, shuffle=False) for testdata in testsets]\n",
    "\n",
    "    def shuffle_loader(self, trainsets, batch_size_train, batch_size_val, train_ratio):\n",
    "        # TODO refactoing to use self\n",
    "        if True:\n",
    "            dataset_length = len(trainsets[0])\n",
    "            assert all(len(trainset) == dataset_length for trainset in trainsets), \"All trainsets must be the same length\"\n",
    "\n",
    "            np.random.shuffle(self.train_set_indices)\n",
    "\n",
    "            train_end = round(train_ratio * dataset_length)\n",
    "            train_indices = self.train_set_indices[:train_end]\n",
    "            val_indices = self.train_set_indices[train_end:]\n",
    "\n",
    "            traindatas = [Subset(trainset, train_indices) for trainset in trainsets]\n",
    "            valdatas = [Subset(trainset, val_indices) for trainset in trainsets]\n",
    "        else:\n",
    "            traindatas = [Subset(trainset, range(round(train_ratio*len(trainset)))) for trainset in trainsets]\n",
    "            valdatas = [Subset(trainset, range(round(train_ratio*len(trainset)), len(trainset))) for trainset in trainsets]\n",
    "        self.trainloader = [DataLoader(traindata, batch_size=batch_size_train, shuffle=False)  for traindata in traindatas]\n",
    "        self.valloader = [DataLoader(valdata, batch_size=batch_size_val, shuffle=False) for valdata in valdatas]\n",
    "\n",
    "\n",
    "    def _pred_loader(self, testsets, batch_size_test, test_shuffle):\n",
    "        return  [DataLoader(testdata, batch_size=batch_size_test, shuffle=False) for testdata in testsets]\n",
    "        \n",
    "    def select_best_ig_threshold(self, ig_outputs, client_preds, server_preds, targets):\n",
    "        import numpy as np\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            ig_outputs (Tensor): shape (N,), sigmoid output from IG model\n",
    "            client_preds (Tensor): shape (N,), predictions from client classifiers\n",
    "            server_preds (Tensor): shape (N,), predictions from server\n",
    "            targets (Tensor): shape (N,), ground truth labels\n",
    "        \"\"\"\n",
    "        thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "        best_acc = 0\n",
    "        best_threshold = 0.5\n",
    "    \n",
    "        for thresh in thresholds:\n",
    "            use_server = ig_outputs >= thresh\n",
    "            final_preds = torch.where(use_server, server_preds, client_preds)\n",
    "            acc = (final_preds == targets).float().mean().item()\n",
    "    \n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_threshold = thresh\n",
    "    \n",
    "            return best_threshold, best_acc\n",
    "\n",
    "    def evaluate_and_select_ig_thresholds(self):\n",
    "        \"\"\"\n",
    "        Evaluate and select the best IG threshold for each client based on validation performance.\n",
    "        Stores best thresholds in self.client_ig_thresholds[i].\n",
    "        \"\"\"\n",
    "        self.client_ig_thresholds = []\n",
    "    \n",
    "        for i, ig_model in enumerate(self.client_ig_models):\n",
    "            ig_model.eval()\n",
    "    \n",
    "            all_ig_outputs = []\n",
    "            all_client_preds = []\n",
    "            all_server_preds = []\n",
    "            all_targets = []\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                for batches in zip(*self.valloader):\n",
    "                    data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "                    target = batches[0][1].to(self.device).long()\n",
    "    \n",
    "                    # Forward pass\n",
    "                    client_activations = [base(data) for base, data in zip(self.client_base_models, data_slices)]\n",
    "                    concat_activations = torch.cat(client_activations, dim=1)\n",
    "                    server_output = self.server_model(concat_activations)\n",
    "                    server_pred = server_output.argmax(dim=1)\n",
    "    \n",
    "                    # This client's outputs\n",
    "                    activation = client_activations[i]\n",
    "                    classifier_pred = self.client_classifier_models[i](activation).argmax(dim=1)\n",
    "                    ig_output = self.client_ig_models[i](activation).squeeze(1)\n",
    "    \n",
    "                    all_ig_outputs.append(ig_output)\n",
    "                    all_client_preds.append(classifier_pred)\n",
    "                    all_server_preds.append(server_pred)\n",
    "                    all_targets.append(target)\n",
    "    \n",
    "            # Stack for evaluation\n",
    "            ig_outputs = torch.cat(all_ig_outputs)\n",
    "            client_preds = torch.cat(all_client_preds)\n",
    "            server_preds = torch.cat(all_server_preds)\n",
    "            targets = torch.cat(all_targets)\n",
    "    \n",
    "            # Select best threshold\n",
    "            best_threshold, best_acc = self.select_best_ig_threshold(\n",
    "                ig_outputs, client_preds, server_preds, targets\n",
    "            )\n",
    "            self.client_ig_thresholds.append(best_threshold)\n",
    "    \n",
    "            print(f\"[Client {i}] Best IG Threshold: {best_threshold:.2f} | Accuracy: {best_acc:.4f}\")\n",
    "        \n",
    "\n",
    "    \n",
    "    def train(self, epoch):\n",
    "        for batch_idx, batches in enumerate(zip(*self.trainloader)):\n",
    "            data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "            target = batches[0][1].to(self.device).long()\n",
    "    \n",
    "            # ====== Base forward passes ======\n",
    "            client_activations = []\n",
    "            classifier_grads_per_client = []\n",
    "            classifier_losses = []\n",
    "            classifier_preds = []\n",
    "    \n",
    "            for data, base_model, classifier_model, optimizer, early_stopper in zip(data_slices, self.client_base_models,  self.client_classifier_models, self.CLIENT_CLASSIFIER_OPTIMIZERS, self.client_early_stopper):\n",
    "                base_model.train()\n",
    "                activation = base_model(data)\n",
    "                activation.requires_grad_()\n",
    "                client_activations.append(activation)\n",
    "                classifier_model.train()\n",
    "                optimizer.zero_grad()\n",
    "                classifier_output = classifier_model(activation)\n",
    "                classifier_pred = classifier_output.argmax(dim=1)\n",
    "                loss = self.LOCAL_CLASSIFIER_CRITERION(classifier_output, target)\n",
    "                classifier_losses.append(loss.item())\n",
    "                grads = torch.autograd.grad(loss, [activation] + list(classifier_model.parameters()), retain_graph=True)\n",
    "                classifier_grads_per_client.append(grads[0])\n",
    "\n",
    "                for param, grad in zip(classifier_model.parameters(), grads[1:]):\n",
    "                    param.grad = grad\n",
    "                optimizer.step()\n",
    "                classifier_preds.append(classifier_pred)\n",
    "            concat_activations = torch.cat(client_activations, dim=1)\n",
    "    \n",
    "            # ====== Server forward and backprop======\n",
    "            self.server_model.train()\n",
    "            self.SERVER_OPTIMIZER.zero_grad()\n",
    "            server_output = self.server_model(concat_activations)\n",
    "            server_loss = self.CRITERION(server_output, target)\n",
    "            server_pred = server_output.argmax(dim=1)\n",
    "                server_grads = torch.autograd.grad(server_loss, [concat_activations] + list(self.server_model.parameters()), retain_graph=True)\n",
    "                #Server Backprop\n",
    "                server_concat_activation_grad = server_grads[0]\n",
    "                server_model_grads = server_grads[1:]\n",
    "                \n",
    "                # Apply gradients manually to model parameters\n",
    "                for param, grad in zip(self.server_model.parameters(), server_model_grads):\n",
    "                    param.grad = grad  # Set .grad for optimizer\n",
    "        \n",
    "                self.SERVER_OPTIMIZER.step()\n",
    "    \n",
    "\n",
    "            # ====== IG forward and backprop ======\n",
    "            ig_grads_per_client = []\n",
    "            for i, (activation, ig_model, ig_optimizer) in enumerate(zip(client_activations, self.client_ig_models, self.CLIENT_IG_OPTIMIZERS)):\n",
    "                ig_model.train()\n",
    "                ig_optimizer.zero_grad()\n",
    "            \n",
    "                # Get IG prediction\n",
    "                ig_output = ig_model(activation).squeeze(1)  # (B,)\n",
    "            \n",
    "                client_wrong = (classifier_pred != target)\n",
    "                server_right = (server_pred == target)\n",
    "                ig_target = (client_wrong & server_right).float() # Shape: (batch_size, 1)\n",
    "                ig_loss = self.LOCAL_IG_CRITERION(ig_output, ig_target)\n",
    "\n",
    "                grads = torch.autograd.grad(ig_loss, [activation] + list(ig_model.parameters()))\n",
    "                ig_grads_per_client.append(grads[0])\n",
    "            \n",
    "                for param, grad in zip(ig_model.parameters(), grads[1:]):\n",
    "                    param.grad = grad\n",
    "                ig_optimizer.step()\n",
    "    \n",
    "            # ====== Base Backprop combined gradients ======\n",
    "            if not self.server_early_stopper.early_stop:\n",
    "                activation_sizes = [act.shape[1] for act in client_activations]\n",
    "                activation_grads_server = torch.split(server_concat_activation_grad, activation_sizes, dim=1)\n",
    "        \n",
    "                for i, (base_model, optimizer, data) in enumerate(zip(self.client_base_models, self.CLIENT_BASE_OPTIMIZERS, data_slices)):\n",
    "                    optimizer.zero_grad()\n",
    "        \n",
    "                    # Combine gradients: server + classifier + IG\n",
    "                    combined_grad = activation_grads_server[i] + classifier_grads_per_client[i] + ig_grads_per_client[i]\n",
    "        \n",
    "                    # Backward through base\n",
    "                    activation = base_model(data)\n",
    "                    activation.backward(combined_grad)\n",
    "                    optimizer.step()\n",
    "                \n",
    "            if batch_idx % self.log_interval == 0:\n",
    "                print(f\"Epoch {epoch} | Batch {batch_idx} | Server Loss: {server_loss.item():.4f} | \"\n",
    "                    f\"Classifier Losses: {[round(x, 4) for x in classifier_losses]}\")\n",
    "\n",
    "    def validate(self):\n",
    "        self.server_model.eval()\n",
    "        \n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batches in enumerate(zip(*self.valloader)):\n",
    "                # batches is tuple of batch from each loader\n",
    "                data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "                target = batches[0][1].to(self.device).long()\n",
    "                client_activations = []\n",
    "                client_val_loss = 0\n",
    "                for data, client_base_model, classifier_model, early_stopper in zip(data_slices, self.client_base_models, self.client_classifier_models, self.client_early_stopper):\n",
    "                    #Client FeedForward\n",
    "                    client_base_model.eval()\n",
    "                    activation = client_base_model(data)\n",
    "                    client_activations.append(activation)\n",
    "                    classifier_output = classifier_model(activation)\n",
    "                    client_loss = self.LOCAL_CLASSIFIER_CRITERION(classifier_output, target).item()\n",
    "                    client_val_loss += client_loss\n",
    "                    client_loss /= len(self.valloader[0].dataset)\n",
    "                    early_stopper(client_loss) \n",
    "                client_val_loss /= self.number_of_clients\n",
    "                concat_activations = torch.cat(client_activations, dim=1)\n",
    "                #Server FeedForward\n",
    "                self.server_model.eval()\n",
    "                output = self.server_model(concat_activations)\n",
    "                server_val_loss = self.CRITERION(output, target).item()\n",
    "                val_loss +=  0.5 * server_val_loss + 0.5 * client_val_loss\n",
    "                server_val_loss /= len(self.valloader[0].dataset)\n",
    "                self.server_early_stopper(server_val_loss)\n",
    "\n",
    "        val_loss /= len(self.valloader[0].dataset)\n",
    "\n",
    "        if self.group_early_stopper.best_loss is None or val_loss < self.group_early_stopper.best_loss:\n",
    "            print(\"Validation loss improved. Saving model...\")\n",
    "            self.save()\n",
    "        self.group_early_stopper(val_loss)\n",
    "\n",
    "    def test(self):\n",
    "        self.server_model.eval()\n",
    "        \n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batches in enumerate(zip(*self.testloader)):\n",
    "                # batches is tuple of batch from each loader\n",
    "                data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "                target = batches[0][1].to(self.device).long()\n",
    "                client_activations = []\n",
    "                for data, client_base_model in zip(data_slices, self.client_base_models):\n",
    "                    #Client FeedForward\n",
    "                    client_base_model.eval()\n",
    "                    activation = client_base_model(data)\n",
    "                    client_activations.append(activation)\n",
    "                concat_activations = torch.cat(client_activations, dim=1)\n",
    "                #Server FeedForward\n",
    "                self.server_model.eval()\n",
    "                output = self.server_model(concat_activations)\n",
    "                test_loss +=  self.CRITERION(output, target).item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(self.testloader[0].dataset)\n",
    "        accuracy = 100. * correct / len(self.testloader[0].dataset)\n",
    "        if self.log: \n",
    "            self.test_losses.append(test_loss)\n",
    "            self.accuracies.append(accuracy)\n",
    "        print(f'\\nTest set: Average loss per Sample: {test_loss:.4f}, Accuracy: {correct}/{len(self.testloader[0].dataset)} '\n",
    "            f'({accuracy:.0f}%)\\n')\n",
    "            \n",
    "        \n",
    "    def test_inferences(self):\n",
    "        self.server_model.eval()\n",
    "        clients_preds = {i: [] for i in range(self.number_of_clients)}\n",
    "        clients_router = {i: [] for i in range(self.number_of_clients)}\n",
    "        test_loss = 0\n",
    "        server_preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batches in enumerate(zip(*self.testloaders)):\n",
    "                # batches is tuple of batch from each loader\n",
    "                data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "                target = batches[0][1].to(self.device).long()\n",
    "                client_activations = []\n",
    "                for i, (data, client_base_model, classifier_model, router_model) in enumerate(zip(data_slices, self.client_base_models, self.client_classifier_models, self.client_ig_models)):\n",
    "                    #Client FeedForward\n",
    "                    client_base_model.eval()\n",
    "                    classifier_model.eval()\n",
    "                    router_model.eval()\n",
    "                    activation = client_base_model(data)\n",
    "                    client_class_logits = classifier_model(activation)\n",
    "                    clients_preds[i] += client_class_logits.argmax(dim=1, keepdim=True)\n",
    "                    client_router_logits = router_model(activation)\n",
    "                    clients_router[i] += client_router_logits.view(-1).tolist()\n",
    "                    client_activations.append(activation)\n",
    "                    \n",
    "                concat_activations = torch.cat(client_activations, dim=1)\n",
    "                #Server FeedForward\n",
    "                self.server_model.eval()\n",
    "                output = self.server_model(concat_activations)\n",
    "                test_loss +=  self.CRITERION(output, target).item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                server_preds += pred.squeeze().tolist()\n",
    "\n",
    "        return clients_preds, clients_router, server_preds\n",
    "            \n",
    "    def run_training(self, trainset, testset):\n",
    "        self.server_early_stopper = EarlyStopper()\n",
    "        self.client_early_stopper = [EarlyStopper() for _ in range(self.number_of_clients)]\n",
    "        self.group_early_stopper = EarlyStopper()\n",
    "        self._to_loader(trainset, testset, \n",
    "            self.model_config.BATCH_SIZE_TRAIN,\n",
    "            self.model_config.BATCH_SIZE_VAL, \n",
    "            self.model_config.BATCH_SIZE_TEST, \n",
    "            self.model_config.TRAIN_SHUFFLE,\n",
    "            self.model_config.VAL_SHUFFLE, \n",
    "            self.model_config.TEST_SHUFFLE,\n",
    "            self.model_config.TRAIN_RATIO)\n",
    "        self.test()\n",
    "        \n",
    "        self.classifier_test()\n",
    "        for epoch in range(1, self.model_config.N_EPOCH + 1):\n",
    "            self.train(epoch)\n",
    "            self.test()\n",
    "            self.classifier_test()\n",
    "            self.validate()\n",
    "            \n",
    "            if self.group_early_stopper.early_stop:\n",
    "                self.early_stop_epoch = epoch\n",
    "                print(\"early_stop_triggered\")\n",
    "                break\n",
    "            self.shuffle_loader(trainset, \n",
    "            self.model_config.BATCH_SIZE_TRAIN,\n",
    "            self.model_config.BATCH_SIZE_VAL, \n",
    "            self.model_config.TRAIN_RATIO)\n",
    "        \n",
    "        print(\"loading best model to server...\")\n",
    "        self.load()\n",
    "\n",
    "    def run_router_threshold_sweep(self, clients_router, thresholds=np.linspace(1.0, 0.0, num=50)):\n",
    "        results = {}\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            percentages = {}\n",
    "            for client_id, logits in clients_router.items():\n",
    "                # logits: list of floats (router outputs from test_inferences)\n",
    "                preds = [1 if logit > threshold else 0 for logit in logits]\n",
    "                num_total = len(preds)\n",
    "                num_true = sum(preds)\n",
    "                percent_true = (num_true / num_total) if num_total > 0 else 0.0\n",
    "                percentages[client_id] = round(percent_true, 4)\n",
    "            \n",
    "            results[float(np.round(threshold, 4))] = percentages\n",
    "\n",
    "        return results\n",
    "    \n",
    "    def hybrid_f1_per_client_individual_threshold(\n",
    "        self,\n",
    "        clients_preds,\n",
    "        clients_router,\n",
    "        server_preds,\n",
    "        targets,\n",
    "        thresholds=np.linspace(1.0, 0.0, num=50)\n",
    "    ):\n",
    "        \"\"\"\n",
    "        For each client and each threshold, compute their own hybrid F1-score\n",
    "        (use client prediction if router > threshold, else use server prediction).\n",
    "\n",
    "        Args:\n",
    "            clients_preds (dict): {client_id: list of predicted labels (tensors or ints)}\n",
    "            clients_router (dict): {client_id: list of router confidence scores (floats)}\n",
    "            server_preds (list): list of server predicted labels\n",
    "            targets (list or tensor): true labels\n",
    "            thresholds (np.array): thresholds to sweep for each client\n",
    "\n",
    "        Returns:\n",
    "            dict: {client_id: {threshold: f1_score (macro)}}\n",
    "        \"\"\"\n",
    "        number_of_clients = len(clients_preds)\n",
    "        num_samples = len(server_preds)\n",
    "\n",
    "        # Flatten predictions and targets\n",
    "        flat_client_preds = {\n",
    "            i: [p.item() if hasattr(p, 'item') else int(p) for p in preds]\n",
    "            for i, preds in clients_preds.items()\n",
    "        }\n",
    "        flat_targets = [t.item() if hasattr(t, 'item') else int(t) for t in targets]\n",
    "        flat_server_preds = [s.item() if hasattr(s, 'item') else int(s) for s in server_preds]\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        for client_id in range(number_of_clients):\n",
    "            client_f1 = {}\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                preds = []\n",
    "                for idx in range(num_samples):\n",
    "                    if clients_router[client_id][idx] > threshold:\n",
    "                        pred = flat_client_preds[client_id][idx]\n",
    "                    else:\n",
    "                        pred = flat_server_preds[idx]\n",
    "                    preds.append(pred)\n",
    "\n",
    "                f1 = f1_score(flat_targets, preds, average='macro')\n",
    "                client_f1[float(np.round(threshold, 4))] = f1\n",
    "\n",
    "            results[client_id] = client_f1\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "    def hybrid_accuracy_per_client_individual_threshold(\n",
    "        self,\n",
    "        clients_preds,\n",
    "        clients_router,\n",
    "        server_preds,\n",
    "        targets,\n",
    "        thresholds=np.linspace(1.0, 0.0, num=50 )\n",
    "    ):\n",
    "        \"\"\"\n",
    "        For each client and each threshold, compute their own hybrid accuracy\n",
    "        (use client prediction if router > threshold, else use server prediction).\n",
    "\n",
    "        Args:\n",
    "            clients_preds (dict): {client_id: list of predicted labels (tensors or ints)}\n",
    "            clients_router (dict): {client_id: list of router confidence scores (floats)}\n",
    "            server_preds (list): list of server predicted labels\n",
    "            targets (list or tensor): true labels\n",
    "            thresholds (np.array): thresholds to sweep for each client\n",
    "\n",
    "        Returns:\n",
    "            dict: {client_id: {threshold: accuracy}}\n",
    "        \"\"\"\n",
    "        number_of_clients = len(clients_preds)\n",
    "        num_samples = len(server_preds)\n",
    "\n",
    "        # Flatten predictions and targets\n",
    "        flat_client_preds = {\n",
    "            i: [p.item() if hasattr(p, 'item') else int(p) for p in preds]\n",
    "            for i, preds in clients_preds.items()\n",
    "        }\n",
    "        flat_targets = [t.item() if hasattr(t, 'item') else int(t) for t in targets]\n",
    "        flat_server_preds = [s.item() if hasattr(s, 'item') else int(s) for s in server_preds]\n",
    "\n",
    "        results = {}\n",
    "\n",
    "        for client_id in range(number_of_clients):\n",
    "            client_acc = {}\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                preds = []\n",
    "                for idx in range(num_samples):\n",
    "                    if clients_router[client_id][idx] > threshold:\n",
    "                        pred = flat_client_preds[client_id][idx]\n",
    "                    else:\n",
    "                        pred = flat_server_preds[idx]\n",
    "                    preds.append(pred)\n",
    "\n",
    "                acc = accuracy_score(flat_targets, preds)\n",
    "                client_acc[float(np.round(threshold, 4))] = acc\n",
    "\n",
    "            results[client_id] = client_acc\n",
    "\n",
    "        return results\n",
    "        \n",
    "\n",
    "    def run_tests(self, testsets): \n",
    "        self.testloaders = [DataLoader(testdata, batch_size=self.model_config.BATCH_SIZE_TEST, shuffle=False) for testdata in testsets]\n",
    "        clients_preds, clients_router, server_preds = self.test_inferences()\n",
    "        coverage_sweep = self.run_router_threshold_sweep(clients_router)\n",
    "        targets =  self.testloaders[0].dataset.targets  \n",
    "        hybrid_sweep = self.hybrid_accuracy_per_client_individual_threshold(\n",
    "            clients_preds=clients_preds,\n",
    "            clients_router=clients_router,\n",
    "            server_preds=server_preds,\n",
    "            targets=self.testloaders[0].dataset.targets\n",
    "        )\n",
    "        hybrid_F1_sweep = self.hybrid_f1_per_client_individual_threshold(\n",
    "            clients_preds=clients_preds,\n",
    "            clients_router=clients_router,\n",
    "            server_preds=server_preds,\n",
    "            targets=self.testloaders[0].dataset.targets\n",
    "        )\n",
    "        return coverage_sweep, hybrid_sweep, hybrid_F1_sweep \n",
    "        \n",
    "    def pred(self, testset,  pred=True):\n",
    "        predictions = []\n",
    "        loader = self._pred_loader(testset, self.model_config.BATCH_SIZE_TEST, self.model_config.TEST_SHUFFLE)\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batches in enumerate(zip(*loader)):\n",
    "                # batches is tuple of batch from each loader\n",
    "                data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "                target = batches[0][1].to(self.device).long()\n",
    "                client_activations = []\n",
    "                for data, client_base_model in zip(data_slices, self.client_base_models):\n",
    "                    #Client FeedForward\n",
    "                    client_base_model.eval()\n",
    "                    activation = client_base_model(data)\n",
    "                    client_activations.append(activation)\n",
    "                concat_activations = torch.cat(client_activations, dim=1)\n",
    "                #Server FeedForward\n",
    "                self.server_model.eval()\n",
    "                output = self.server_model(concat_activations)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                predictions = predictions + pred.squeeze().tolist()\n",
    "        return predictions\n",
    "\n",
    "    def save(self):\n",
    "        result_path = f\"./results/hybrid/v1/{self.data_config.DATASET_NAME}/{self.seed}\"\n",
    "        os.makedirs(result_path, exist_ok=True)\n",
    "        model_path = os.path.join(result_path, f'model_server_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        optimizer_path = os.path.join(result_path, f'optimizer_server_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        torch.save(self.server_model.state_dict(), model_path)\n",
    "        torch.save(self.SERVER_OPTIMIZER.state_dict(), optimizer_path)\n",
    "\n",
    "        client_result_path =os.path.join(result_path, \"clients\")\n",
    "        os.makedirs(client_result_path, exist_ok=True)\n",
    "        for i, client_base_model in enumerate(self.client_base_models): \n",
    "            model_path = os.path.join(client_result_path, f'model_client_base_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            optimizer_path = os.path.join(client_result_path, f'optimizer_client_base_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            torch.save(client_base_model.state_dict(), model_path)\n",
    "            torch.save(self.CLIENT_BASE_OPTIMIZERS[i].state_dict(), optimizer_path)\n",
    "                    \n",
    "        for i, client_classifier_model in enumerate(self.client_classifier_models): \n",
    "            model_path = os.path.join(client_result_path, f'model_client_classifier_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            optimizer_path = os.path.join(client_result_path, f'optimizer_classifier_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            torch.save(client_classifier_model.state_dict(), model_path)\n",
    "            torch.save(self.CLIENT_CLASSIFIER_OPTIMIZERS[i].state_dict(), optimizer_path)\n",
    "        \n",
    "        for i, client_router_model in enumerate(self.client_ig_models): \n",
    "            model_path = os.path.join(client_result_path, f'model_client_router_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            optimizer_path = os.path.join(client_result_path, f'optimizer_router_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            torch.save(client_router_model.state_dict(), model_path)\n",
    "            torch.save(self.CLIENT_IG_OPTIMIZERS[i].state_dict(), optimizer_path)\n",
    "                   \n",
    "    def load(self):\n",
    "        result_path = f\"./results/hybrid/v1/{self.data_config.DATASET_NAME}/{self.seed}\"\n",
    "        model_path = os.path.join(result_path, f'model_server_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        optimizer_path = os.path.join(result_path, f'optimizer_server_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        network_state_dict = torch.load(model_path)\n",
    "        self.server_model.load_state_dict(network_state_dict)\n",
    "        optimizer_state_dict = torch.load(optimizer_path)\n",
    "        self.SERVER_OPTIMIZER.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "        client_result_path = os.path.join(result_path, \"clients\")\n",
    "        for i, (client_base_model, model_optimizer) in enumerate(zip(self.client_base_models, self.CLIENT_BASE_OPTIMIZERS)): \n",
    "            model_path = os.path.join(client_result_path, f'model_client_base_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            optimizer_path = os.path.join(client_result_path, f'optimizer_client_base_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            network_state_dict = torch.load(model_path)\n",
    "            client_base_model.load_state_dict(network_state_dict)\n",
    "            optimizer_state_dict = torch.load(optimizer_path)\n",
    "            model_optimizer.load_state_dict(optimizer_state_dict)\n",
    "        \n",
    "        for i, (client_classifier_model, model_optimizer) in enumerate(zip(self.client_classifier_models, self.CLIENT_CLASSIFIER_OPTIMIZERS)): \n",
    "            model_path = os.path.join(client_result_path, f'model_client_classifier_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            optimizer_path = os.path.join(client_result_path, f'optimizer_classifier_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            network_state_dict = torch.load(model_path)\n",
    "            client_classifier_model.load_state_dict(network_state_dict)\n",
    "            optimizer_state_dict = torch.load(optimizer_path)\n",
    "            model_optimizer.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "        for i, (client_router_model, model_optimizer) in enumerate(zip(self.client_ig_models, self.CLIENT_IG_OPTIMIZERS)): \n",
    "            model_path = os.path.join(client_result_path, f'model_client_router_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            optimizer_path = os.path.join(client_result_path, f'optimizer_router_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            network_state_dict = torch.load(model_path)\n",
    "            client_router_model.load_state_dict(network_state_dict)\n",
    "            optimizer_state_dict = torch.load(optimizer_path)\n",
    "            model_optimizer.load_state_dict(optimizer_state_dict)\n",
    "                   \n",
    "                            \n",
    "    def classifier_test(self):\n",
    "        test_loss_values = [0 for c in self.client_base_models]\n",
    "        correct_values = [0 for c in self.client_base_models]\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batches in enumerate(zip(*self.testloader)):\n",
    "                data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "                target = batches[0][1].to(self.device).long()\n",
    "                for client_idx, client in enumerate(zip(data_slices, self.client_base_models, self.client_classifier_models)):\n",
    "                    data, client_base_model, classifier_model = client \n",
    "                    client_base_model.train()\n",
    "                    activation = client_base_model(data)\n",
    "                    classifier_output = classifier_model(activation)\n",
    "                    test_loss_values[client_idx] +=  self.LOCAL_CLASSIFIER_CRITERION(classifier_output, target).item()\n",
    "                    pred = classifier_output.argmax(dim=1, keepdim=True)\n",
    "                    correct_values[client_idx]+= pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss_values = [t/ len(self.testloader[0].dataset) for t in test_loss_values]\n",
    "        accuracy_values = [100. * c / len(self.testloader[0].dataset) for c in correct_values]\n",
    "\n",
    "        if self.log: \n",
    "            self.test_losses.append(test_loss_values)\n",
    "            self.accuracies.append(accuracy_values)\n",
    "        print(f'\\nTest set: Average loss per Sample: {test_loss_values}, Accuracy: {correct_values}/{len(self.testloader[0].dataset)}'\n",
    "            f'({accuracy_values}%)\\n')\n",
    "\n",
    "    def gate_pred(self): \n",
    "        for batch_idx, batches in enumerate(zip(*self.testloader)):\n",
    "            data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "            target = batches[0][1].to(self.device).long()\n",
    "            ig_outputs = []\n",
    "            for client_idx, client in enumerate(zip(data_slices, self.client_base_models, self.client_ig_models)):\n",
    "                data, client_base_model, classifier_model, client_ig_model = client\n",
    "                #Client FeedForward\n",
    "                client_base_model.eval()\n",
    "                activation = client_base_model(data)\n",
    "                ig_output = client_ig_model(activation) \n",
    "                ig_outputs.append(ig_output)\n",
    "            return ig_outputs, target\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eadb8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "from federated_inference.common.environment import  DataMode, TransformType\n",
    "from federated_inference.simulations.simulation import Simulation\n",
    "from federated_inference.simulations.utils import *\n",
    "\n",
    "class HybridSplitSimulation(Simulation): \n",
    "    def __init__(self, seed, data_config, transform_config, server_model, client_base_model, client_classifier_model, client_ig_model, transform_type: TransformType = TransformType.FULL_STRIDE_PARTITION, exist=False):\n",
    "        self.seed = seed\n",
    "        self.data_config = data_config\n",
    "        self.transform_config = transform_config\n",
    "        self.server_model_config = HybridSplitModelConfiguration(server_model, client_base_model, client_classifier_model, client_ig_model)\n",
    "        self.data_mode = DataMode.VERTICAL\n",
    "        self.transform_type = transform_type\n",
    "        self.dataset =  self.load_data(data_config)\n",
    "        self.client_datasets, self.transformation = self.transform_data(self.dataset, data_mode = self.data_mode, transform_config = transform_config, transform_type = self.transform_type)\n",
    "        self.clients = [HybridSplitClient(idx, seed, data_config, self.server_model_config, dataset, data_config.LABELS) for idx, dataset in enumerate(self.client_datasets)]\n",
    "        self.server = HybridSplitServer(0, seed, self.server_model_config , self.data_config)\n",
    "\n",
    "    def train(self): \n",
    "        datasets = [client.send_all() for client in self.clients]\n",
    "        testsets = [client.request_pred(pred_all = True, keep_label = True) for client in self.clients]\n",
    "        self.server.run_training(datasets, testsets)\n",
    "\n",
    "    def test_inference(self):\n",
    "        testsets = [client.request_pred(pred_all = True, keep_label = True) for client in self.clients]\n",
    "        predictions = self.server.pred(testsets)\n",
    "        self.clients[0].check(predictions)\n",
    "        #self.collect_results(self.seed, save = True)\n",
    "\n",
    "    def collect_results(self, name: str, save: bool = True, figures: bool = False):\n",
    "        from IPython.display import display\n",
    "\n",
    "        self.results = {\n",
    "            'seed': name,\n",
    "            'client': [],\n",
    "            'server': {}\n",
    "        }\n",
    "\n",
    "        if figures:\n",
    "            fig = create_simulation_image_subplots(self)\n",
    "            display(fig)\n",
    "\n",
    "        # Collect server results\n",
    "        self.results['server'] = self._gather_server_results(self.server)\n",
    "\n",
    "        # Collect results for the first (and only) client\n",
    "        client = self.clients[0]\n",
    "        client_result = self._gather_client_result(client, figures)\n",
    "        self.results['client'].append(client_result)\n",
    "\n",
    "        # Save results\n",
    "        if save:\n",
    "            self._save_results(str(name), base_dir=\"naive\")\n",
    "        return self.results\n",
    "\n",
    "    def _gather_server_results(self, server):\n",
    "        return {\n",
    "            'training_losses': server.train_losses,\n",
    "            'test_losses': server.test_losses\n",
    "        }\n",
    "\n",
    "    def _gather_client_result(self, client, figures):\n",
    "        from IPython.display import display\n",
    "\n",
    "        result = {\n",
    "            'idx': client.idx,\n",
    "            'cm': client.cm.to_json(orient='split')\n",
    "        }\n",
    "\n",
    "        analysis, df_cm_per = cm_analysis(client)\n",
    "        result['cm_analysis'] = analysis\n",
    "\n",
    "        # Extract relevant class indices\n",
    "        indices = [\n",
    "            analysis['correct']['most_correct_class'],\n",
    "            analysis['wrong']['most_misclassified_class']\n",
    "        ]\n",
    "        indices += [i for i in [analysis['wrong']['wrong_from'], analysis['wrong']['wrong_to']] if i not in indices]\n",
    "\n",
    "        # Add performance metrics\n",
    "        result.update({\n",
    "            'accuracy': analysis[\"performance\"][\"accuracy\"],\n",
    "            'precision': analysis[\"performance\"][\"precision\"],\n",
    "            'recall': analysis[\"performance\"][\"recall\"]\n",
    "        })\n",
    "\n",
    "        # Generate figures if needed\n",
    "        if figures:\n",
    "            display(plot_test_loss(client.test_losses, 1, client.idx, \"Test\"))\n",
    "            fig, subplot_indices = create_client_image_subplots(self, [client.idx], 8, keys=indices)\n",
    "            display(fig)\n",
    "            result['client_image_subplots_ids'] = subplot_indices\n",
    "            fig = print_cm_heat(df_cm_per, client.idx)\n",
    "            display(fig)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _save_results(self, name, base_dir=\"ig\"):\n",
    "        import os\n",
    "        import json\n",
    "\n",
    "        result_path = os.path.join(\"./results\", base_dir , self.data_config.DATASET_NAME, name)\n",
    "        \n",
    "        os.makedirs(result_path, exist_ok=True)\n",
    "        file_path = os.path.join(result_path, \"simulation.json\")\n",
    "\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(self.results, f, indent=4)\n",
    "        print(\"Results saved to JSON.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0196127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "client_mapping = {\n",
    "    0: \"left top (LT)\",\n",
    "    1: \"right top (RT)\",\n",
    "    2: \"left bottom (LB)\",\n",
    "    3: \"right bottom (RB)\"\n",
    "}\n",
    "\n",
    "def plot_accuracy_vs_coverage(coverage, hybrid_accuracy):\n",
    "    \"\"\"\n",
    "    Plot hybrid accuracy vs. coverage per client.\n",
    "    Coverage is flipped so that 1.0 coverage corresponds to threshold=0,\n",
    "    and 0.0 coverage corresponds to threshold=1.\n",
    "\n",
    "    Args:\n",
    "        coverage (dict): {threshold: {client_id: coverage_value}}\n",
    "        hybrid_accuracy (dict): {client_id: {threshold: accuracy_value}}\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort thresholds ascending (from 0.0 to 1.0) because coverage is reversed\n",
    "    thresholds = sorted(coverage.keys())\n",
    "    clients = sorted(hybrid_accuracy.keys())\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Collect accuracies at coverage = 1.0 for all clients\n",
    "    best_acc_at_cov1 = []\n",
    "\n",
    "    for client_id in clients:\n",
    "        # Extract coverage and accuracy arrays matching thresholds\n",
    "        covs = np.array([coverage[t][client_id] for t in thresholds])\n",
    "        accs = np.array([hybrid_accuracy[client_id][t] for t in thresholds])\n",
    "        flipped = (1-covs)\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=flipped,\n",
    "                y=accs,\n",
    "                mode='lines+markers',\n",
    "                name=f'Client {client_mapping[client_id]}'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Find accuracy where coverage == 1.0 (or very close to it)\n",
    "        # Use np.isclose for floating point safety\n",
    "        mask = np.isclose(covs, 1.0)\n",
    "        if np.any(mask):\n",
    "            best_acc_at_cov1.append(accs[mask][0])\n",
    "\n",
    "    # Add horizontal line at best accuracy at coverage=1.0 (max over clients)\n",
    "    if best_acc_at_cov1:\n",
    "        max_acc = max(best_acc_at_cov1)\n",
    "        fig.add_hline(\n",
    "            y=max_acc,\n",
    "            line_dash=\"dash\",\n",
    "            line_color=\"red\",\n",
    "            annotation_text=f\"Best local accuracy: {max_acc:.3f}\",\n",
    "            annotation_position=\"top right\"\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Hybrid Accuracy vs. Local Coverage per Client',\n",
    "        xaxis=dict(\n",
    "            title='Remote Coverage (Fraction of samples processed by the Cloud)',\n",
    "            range=[0, 1],\n",
    "            autorange=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Hybrid Accuracy',\n",
    "            range=[0, 1],\n",
    "            autorange=False\n",
    "        ),\n",
    "        legend_title='Clients',\n",
    "        width=800,\n",
    "        height=500,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483fb10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in [1,2,3]:\n",
    "    set_seed(seed)\n",
    "    data_config = DataConfiguration('MNIST')\n",
    "    transform_config = DataTransformConfiguration()\n",
    "    simulation2 = HybridSplitSimulation(seed, data_config, transform_config, GlobalHybridSplitCNN, HybridSplitBase, LocalHybridSplitClassifierHead, RouterHead)\n",
    "    simulation2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e247c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class OnDeviceMNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = \"OnDeviceMNISTModel\"\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # 16x14x14\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # 32x14x14\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2),  # 32x7x7\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 7 * 7, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten dynamically\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bd060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb72033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
