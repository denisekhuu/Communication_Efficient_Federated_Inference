{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import random \n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)                # CPU\n",
    "    torch.cuda.manual_seed(seed)           # Current GPU\n",
    "    torch.cuda.manual_seed_all(seed)       # All GPUs\n",
    "    np.random.seed(seed)                   # NumPy\n",
    "    random.seed(seed)                      # Python random\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from federated_inference.dataset import MNISTDataset, FMNISTDataset, CIFAR10Dataset\n",
    "from federated_inference.common.environment import DataSetEnum\n",
    "\n",
    "class DataConfiguration():\n",
    "    \n",
    "    #MNIST_FASHION_DATASET Configurations\n",
    "    FMNIST_NAME = 'FMNIST'\n",
    "    FMNIST_DATASET_PATH = os.path.join('./data/fmnist')\n",
    "    FMNIST_LABELS = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker',  'Bag', 'Ankle Boot']\n",
    "    \n",
    "    #MNIST_DATASET Configurations\n",
    "    MNIST_NAME = 'MNIST'\n",
    "    MNIST_DATASET_PATH = os.path.join('./data/mnist')\n",
    "    \n",
    "    #CIFAR_DATASET Configurations\n",
    "    CIFAR10_NAME = 'CIFAR10'\n",
    "    CIFAR10_DATASET_PATH = os.path.join('./data/cifar10')\n",
    "    CIFAR10_LABELS = ['Plane', 'Car', 'Bird', 'Cat','Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "\n",
    "    def __init__(self, dataset_name : str = None):\n",
    "        load_dotenv(override=True)\n",
    "        self.DATASET_NAME = dataset_name if dataset_name else os.getenv('DATASET_NAME', 'MNIST')\n",
    "        if self.DATASET_NAME == DataSetEnum.MNIST.value: \n",
    "            self.INSTANCE_SIZE = (1, 28, 28)\n",
    "            self.DATASET = DataSetEnum.MNIST\n",
    "            self.DATASET_PATH = os.path.join(os.getenv('DATASET_PATH', self.MNIST_DATASET_PATH))\n",
    "            self.LABELS = range(10)\n",
    "        if self.DATASET_NAME == DataSetEnum.FMNIST.value: \n",
    "            self.INSTANCE_SIZE = (1, 28, 28)\n",
    "            self.DATASET = DataSetEnum.FMNIST\n",
    "            self.DATASET_PATH = os.path.join(os.getenv('DATASET_PATH', self.FMNIST_DATASET_PATH))\n",
    "            self.LABELS = self.FMNIST_LABELS\n",
    "        if self.DATASET_NAME == DataSetEnum.CIFAR10.value:\n",
    "            self.INSTANCE_SIZE = (1, 32, 32)\n",
    "            self.DATASET = DataSetEnum.CIFAR10\n",
    "            self.DATASET_PATH = os.path.join(os.getenv('DATASET_PATH', self.CIFAR10_DATASET_PATH))\n",
    "            self.LABELS =  self.CIFAR10_LABELS\n",
    "\n",
    "    def __dict__(self):\n",
    "        return {\n",
    "            \"dataset_name\": self.DATASET_NAME, \n",
    "            \"labels\": list(self.LABELS),\n",
    "            \"size\": self.INSTANCE_SIZE\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58cf7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "class OnDeviceModelConfiguration():\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                          else \"mps\" if torch.backends.mps.is_available()\n",
    "                          else \"cpu\")\n",
    "\n",
    "    def __init__(self,  \n",
    "        model: nn.Module, \n",
    "        learning_rate: float = 0.001, \n",
    "        batch_size_train: int = 64, \n",
    "        batch_size_val: int = 64, \n",
    "        batch_size_test: int = 64, \n",
    "        train_shuffle: bool = True, \n",
    "        val_shuffle: bool = False, \n",
    "        test_suffle: bool = False, \n",
    "        n_epochs: int = 60,\n",
    "        train_ratio: float = 0.8):\n",
    "        self.MODEL = model().to(self.DEVICE)\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "        self.TRAIN_RATIO = train_ratio\n",
    "        self.BATCH_SIZE_TRAIN = batch_size_train\n",
    "        self.BATCH_SIZE_VAL = batch_size_val\n",
    "        self.BATCH_SIZE_TEST = batch_size_test\n",
    "        self.TRAIN_SHUFFLE = train_shuffle\n",
    "        self.VAL_SHUFFLE = val_shuffle\n",
    "        self.TEST_SHUFFLE = test_suffle\n",
    "        self.N_EPOCH = n_epochs\n",
    "        self.CRITERION = nn.CrossEntropyLoss()\n",
    "        self.CRITERION_NAME = \"CrossEntropyLoss\"\n",
    "        self.OPTIMIZER = optim.Adam(self.MODEL.parameters() , lr=learning_rate, weight_decay=1e-4) \n",
    "        self.OPTIMIZER_NAME = \"Adam\"\n",
    "\n",
    "    def set_optimizer(self, optimizer, name):\n",
    "        self.OPTIMIZER = optimizer\n",
    "        self.OPTIMIZER_NAME = name\n",
    "\n",
    "    def set_criterion(self, criterion, name): \n",
    "        self.CRITERION = criterion\n",
    "        self.CRITERION_NAME = name\n",
    "\n",
    "\n",
    "    def __dict__(self):\n",
    "        return {\n",
    "            \"model_name\": self.MODEL.name,\n",
    "            \"learning_rate\": self.LEARNING_RATE, \n",
    "            \"train_ratio\": self.TRAIN_RATIO,\n",
    "            \"batch_size_train\": self.BATCH_SIZE_TRAIN,\n",
    "            \"batch_size_val\": self.BATCH_SIZE_VAL,\n",
    "            \"batch_size_test\": self.BATCH_SIZE_TEST, \n",
    "            \"train_shuffle\": self.TRAIN_SHUFFLE,\n",
    "            \"val_shuffle\": self.VAL_SHUFFLE,\n",
    "            \"test_shuffle\": self.TEST_SHUFFLE,\n",
    "            \"n_epoch\": self.N_EPOCH, \n",
    "            \"optimizer\":  self.OPTIMIZER_NAME, \n",
    "            \"criterion\": self.CRITERION_NAME\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f906e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "class OnDeviceModelConfiguration():\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                          else \"mps\" if torch.backends.mps.is_available()\n",
    "                          else \"cpu\")\n",
    "\n",
    "    def __init__(self,  \n",
    "        model: nn.Module, \n",
    "        learning_rate: float = 0.001, \n",
    "        batch_size_train: int = 64, \n",
    "        batch_size_val: int = 64, \n",
    "        batch_size_test: int = 64, \n",
    "        train_shuffle: bool = True, \n",
    "        val_shuffle: bool = False, \n",
    "        test_suffle: bool = False, \n",
    "        n_epochs: int = 30,\n",
    "        train_ratio: float = 0.8):\n",
    "        self.MODEL = model().to(self.DEVICE)\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "        self.TRAIN_RATIO = train_ratio\n",
    "        self.BATCH_SIZE_TRAIN = batch_size_train\n",
    "        self.BATCH_SIZE_VAL = batch_size_val\n",
    "        self.BATCH_SIZE_TEST = batch_size_test\n",
    "        self.TRAIN_SHUFFLE = train_shuffle\n",
    "        self.VAL_SHUFFLE = val_shuffle\n",
    "        self.TEST_SHUFFLE = test_suffle\n",
    "        self.N_EPOCH = n_epochs\n",
    "        self.CRITERION = nn.CrossEntropyLoss()\n",
    "        self.CRITERION_NAME = \"CrossEntropyLoss\"\n",
    "        self.OPTIMIZER = optim.Adam(self.MODEL.parameters() , lr=2*learning_rate, weight_decay=0) \n",
    "        self.OPTIMIZER_NAME = \"Adam\"\n",
    "\n",
    "    def set_optimizer(self, optimizer, name):\n",
    "        self.OPTIMIZER = optimizer\n",
    "        self.OPTIMIZER_NAME = name\n",
    "\n",
    "    def set_criterion(self, criterion, name): \n",
    "        self.CRITERION = criterion\n",
    "        self.CRITERION_NAME = name\n",
    "\n",
    "\n",
    "    def __dict__(self):\n",
    "        return {\n",
    "            \"model_name\": self.MODEL.name,\n",
    "            \"learning_rate\": self.LEARNING_RATE, \n",
    "            \"train_ratio\": self.TRAIN_RATIO,\n",
    "            \"batch_size_train\": self.BATCH_SIZE_TRAIN,\n",
    "            \"batch_size_val\": self.BATCH_SIZE_VAL,\n",
    "            \"batch_size_test\": self.BATCH_SIZE_TEST, \n",
    "            \"train_shuffle\": self.TRAIN_SHUFFLE,\n",
    "            \"val_shuffle\": self.VAL_SHUFFLE,\n",
    "            \"test_shuffle\": self.TEST_SHUFFLE,\n",
    "            \"n_epoch\": self.N_EPOCH, \n",
    "            \"optimizer\":  self.OPTIMIZER_NAME, \n",
    "            \"criterion\": self.CRITERION_NAME\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804fb77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformConfiguration(): \n",
    "\n",
    "    def __init__(self, tensor_size = [1,28,28], method_name = 'full', mask_size = [14,14], dimensions = [1,2], stride = 14, n_position = None, drop_p = None):\n",
    "        self.TENSOR_SIZE = tensor_size\n",
    "        self.METHOD_NAME = method_name\n",
    "        self.MASK_SIZE = mask_size \n",
    "        self.DIMENSIONS = dimensions\n",
    "        self.STRIDE = stride\n",
    "        self.N_POSITION = n_position\n",
    "        self.DROP_P = drop_p\n",
    "\n",
    "    def __dict__(self):\n",
    "        return {\n",
    "            \"tensor_size\": self.TENSOR_SIZE, \n",
    "            \"method_name\": self.METHOD_NAME,\n",
    "            \"mask_size\": self.MASK_SIZE,\n",
    "            \"dimensions\": self.DIMENSIONS,\n",
    "            \"stride\": self.STRIDE,\n",
    "            \"n_position\": self.N_POSITION,\n",
    "            \"drop_p\": self.DROP_P,\n",
    "\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdd45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class OnDeviceMNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = \"OnDeviceMNISTModel\"\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # 16x14x14\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # 32x14x14\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2d(2),  # 32x7x7\n",
    "\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 7 * 7, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # flatten dynamically\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from federated_inference.common.environment import Member\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from collections.abc import Iterable\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class EarlyStopper():\n",
    "    def __init__(self, patience = 20, min_delta =  0.00001):\n",
    "        self.patience = patience \n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0 \n",
    "        self.best_loss = None \n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None: \n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else: \n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        \n",
    "class OnDeviceVerticalClient():\n",
    "\n",
    "    def __init__(self, \n",
    "            idx, \n",
    "            seed,\n",
    "            model_config: OnDeviceModelConfiguration,\n",
    "            data_config: DataConfiguration,\n",
    "            dataset: TorchDataset,\n",
    "            labels,\n",
    "            log: bool = True, \n",
    "            log_interval: int = 100,\n",
    "            save_interval: int = 20\n",
    "        ):\n",
    "        self.idx = idx\n",
    "        self.seed = seed\n",
    "        self.data = dataset\n",
    "        self.data_config = data_config\n",
    "        self.labels = labels\n",
    "        self.numerical_labels = range(len(labels))\n",
    "        self.member_type = Member.CLIENT\n",
    "        self.model_config = model_config\n",
    "        self.n_epoch = model_config.N_EPOCH\n",
    "        self.device = model_config.DEVICE\n",
    "        self.model = model_config.MODEL\n",
    "        self.optimizer = model_config.OPTIMIZER\n",
    "        self.criterion = model_config.CRITERION\n",
    "        self.costs = []\n",
    "\n",
    "        self.log = log\n",
    "        self.log_interval = log_interval\n",
    "        self.save_interval = save_interval\n",
    "\n",
    "        if self.log: \n",
    "            self.train_losses = []\n",
    "            self.test_losses = []\n",
    "            self.accuracies = []\n",
    "\n",
    "    def select_subset(self, ids: Iterable[int], set_type: str = \"train\"):\n",
    "        if set_type == \"test\":\n",
    "            return Subset(self.data.test_dataset, ids)\n",
    "        else: \n",
    "            return Subset(self.data.train_dataset, ids)\n",
    "\n",
    "\n",
    "    def _to_loader(self, trainset, testset, batch_size_train, batch_size_val, batch_size_test, train_shuffle, val_shuffle, test_shuffle, train_ratio):\n",
    "        self.train_set_indices = np.arange(len(trainset))\n",
    "        traindata = Subset(trainset, range(round(train_ratio*len(trainset))))\n",
    "        valdata = Subset(trainset, range(round(train_ratio*len(trainset)), len(trainset)))\n",
    "        self.trainloader = DataLoader(traindata, batch_size=batch_size_train, shuffle= train_shuffle) \n",
    "        self.valloader = DataLoader(valdata, batch_size=batch_size_val, shuffle= val_shuffle) \n",
    "        self.testloader = DataLoader(testset, batch_size=batch_size_test, shuffle=test_shuffle)\n",
    "\n",
    "    def shuffle_loader(self, trainset, batch_size_train, batch_size_val, train_ratio):\n",
    "        np.random.shuffle(self.train_set_indices)\n",
    "        dataset_length = len(self.train_set_indices)\n",
    "        train_end = round(train_ratio * dataset_length)\n",
    "        train_indices = self.train_set_indices[:train_end]\n",
    "        val_indices = self.train_set_indices[train_end:]\n",
    "        traindata = Subset(trainset, train_indices)\n",
    "        valdata = Subset(trainset, val_indices)\n",
    "        self.valloader = DataLoader(valdata, batch_size=batch_size_val, shuffle=False) \n",
    "        self.trainloader = DataLoader(traindata, batch_size=batch_size_train, shuffle=False) \n",
    "\n",
    "    def _pred_loader(self, testset, batch_size_test, test_shuffle):\n",
    "        return DataLoader(testset, batch_size=batch_size_test, shuffle=test_shuffle)\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self.model.train()\n",
    "        for batch_idx, (data, target) in enumerate(self.trainloader):\n",
    "            data = data.to(self.model_config.DEVICE).float()\n",
    "            target = target.to(self.model_config.DEVICE).long()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, target)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if batch_idx % self.save_interval == 0: \n",
    "                self.train_losses.append(loss.item())\n",
    "            if self.log and batch_idx % self.log_interval == 0:\n",
    "                print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(self.trainloader.dataset)} '\n",
    "                    f'({100. * batch_idx / len(self.trainloader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "\n",
    "        val_loss = 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.valloader:\n",
    "                data = data.to(self.model_config.DEVICE).float()\n",
    "                target = target.to(self.model_config.DEVICE).long()\n",
    "                output = self.model(data)\n",
    "                val_loss += self.criterion(output, target).item()\n",
    "        val_loss /= len(self.valloader.dataset)\n",
    "\n",
    "        if self.early_stopper.best_loss is None or val_loss < self.early_stopper.best_loss:\n",
    "            print(\"Validation loss improved. Saving model...\")\n",
    "            self.save()\n",
    "        self.early_stopper(val_loss)\n",
    "\n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.testloader:\n",
    "                data = data.to(self.model_config.DEVICE).float()\n",
    "                target = target.to(self.model_config.DEVICE).long()\n",
    "                output = self.model(data)\n",
    "                test_loss += self.criterion(output, target).item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(self.testloader.dataset)\n",
    "        accuracy = 100. * correct / len(self.testloader.dataset)\n",
    "        if self.log: \n",
    "            self.test_losses.append(test_loss)\n",
    "            self.accuracies.append(accuracy)\n",
    "        print(f'\\nTest set: Average loss per sample: {test_loss:.4f}, Accuracy: {correct}/{len(self.testloader.dataset)} '\n",
    "            f'({accuracy:.0f}%)\\n')\n",
    "\n",
    "    def run_training(self):\n",
    "        trainset = self.data.train_dataset\n",
    "        testset = self.data.test_dataset\n",
    "        self.early_stopper = EarlyStopper()\n",
    "        self._to_loader(trainset, testset, \n",
    "            self.model_config.BATCH_SIZE_TRAIN,\n",
    "            self.model_config.BATCH_SIZE_VAL, \n",
    "            self.model_config.BATCH_SIZE_TEST, \n",
    "            self.model_config.TRAIN_SHUFFLE,\n",
    "            self.model_config.VAL_SHUFFLE, \n",
    "            self.model_config.TEST_SHUFFLE,\n",
    "            self.model_config.TRAIN_RATIO)\n",
    "        self.test()\n",
    "        for epoch in range(1, self.model_config.N_EPOCH + 1):\n",
    "            self.train(epoch)\n",
    "            self.test()\n",
    "            if self.early_stopper.early_stop:\n",
    "                self.early_stop_epoch = epoch\n",
    "                print(\"early_stop_triggered\")\n",
    "                break\n",
    "            self.shuffle_loader(trainset, \n",
    "            self.model_config.BATCH_SIZE_TRAIN,\n",
    "            self.model_config.BATCH_SIZE_VAL, \n",
    "            self.model_config.TRAIN_RATIO)\n",
    "                \n",
    "            \n",
    "    def save(self):\n",
    "        result_path = f\"./results/ondevice/{self.data_config.DATASET_NAME}/{self.seed}\"\n",
    "        os.makedirs(result_path, exist_ok=True)\n",
    "        model_path = os.path.join(result_path, f'model_client_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        optimizer_path = os.path.join(result_path, f'optimizer_client_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "        torch.save(self.optimizer.state_dict(), optimizer_path)\n",
    "\n",
    "\n",
    "    def load(self):\n",
    "        result_path = f\"./results/ondevice/{self.data_config.DATASET_NAME}/{self.seed}\"\n",
    "        model_path = os.path.join(result_path, f'model_client_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        optimizer_path = os.path.join(result_path, f'optimizer_client_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        network_state_dict = torch.load(model_path)\n",
    "        self.model.load_state_dict(network_state_dict)\n",
    "        optimizer_state_dict = torch.load(optimizer_path)\n",
    "        self.optimizer.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "    def pred(self):\n",
    "        predictions = []\n",
    "        testset = self.data.test_dataset\n",
    "        testloader = self._pred_loader(testset, self.model_config.BATCH_SIZE_TEST, self.model_config.TEST_SHUFFLE)\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in testloader :\n",
    "                data = data.to(self.model_config.DEVICE).float()\n",
    "                target = target.to(self.model_config.DEVICE).long()\n",
    "                output = self.model(data)\n",
    "                test_loss += self.criterion(output, target).item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                predictions = predictions + pred.squeeze().tolist()\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def check(self, predicted_labels,  pred_all: bool= True):\n",
    "        from sklearn.metrics import accuracy_score, precision_score, recall_score,  confusion_matrix\n",
    "        import pandas as pd\n",
    "        if pred_all:\n",
    "            true_labels = self.data.test_dataset.targets\n",
    "            accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "            precision = precision_score(true_labels, predicted_labels, average='macro')  # or 'weighted'\n",
    "            recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "            print(\"\\n=== Metrics ===\")\n",
    "            print(f\"Accuracy : {accuracy:.4f}\")\n",
    "            print(f\"Precision: {precision:.4f}\")\n",
    "            print(f\"Recall   : {recall:.4f}\")\n",
    "            cm = confusion_matrix(self.data.test_dataset.targets, predicted_labels, labels=self.numerical_labels)\n",
    "            self.cm = pd.DataFrame(cm, index=[f'True {l}' for l in self.labels],\n",
    "                                    columns=[f'Pred {l}' for l in self.labels])\n",
    "            self.accuracy = accuracy \n",
    "            self.precision = precision \n",
    "            self.recall = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a7da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from federated_inference.simulations.simulation import Simulation\n",
    "from federated_inference.common.environment import TransformType, DataMode  \n",
    "import torch.nn as nn\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from federated_inference.simulations.utils import *\n",
    "\n",
    "class OnDeviceVerticalSimulation(Simulation): \n",
    "    def __init__(self, \n",
    "                 data_config: DataConfiguration, \n",
    "                 transform_config: DataTransformConfiguration, \n",
    "                 seed: int, \n",
    "                 model: nn.Module,\n",
    "                 transform_type:  TransformType = TransformType.FULL_STRIDE_PARTITION, \n",
    "                 exist = False):\n",
    "\n",
    "        self.data_config = data_config\n",
    "        self.transform_config = transform_config\n",
    "        self.seed = seed\n",
    "        self.data_mode = DataMode.VERTICAL\n",
    "        self.transform_type = transform_type\n",
    "        self.dataset =  self.load_data(data_config)\n",
    "        self.client_datasets, self.transformation = self.transform_data(self.dataset, data_mode = self.data_mode, transform_config = transform_config, transform_type = self.transform_type)\n",
    "        self.clients = [OnDeviceVerticalClient(idx, \n",
    "                                               seed, \n",
    "                                               OnDeviceModelConfiguration(model), \n",
    "                                               data_config,\n",
    "                                               dataset, \n",
    "                                               data_config.LABELS) for idx, dataset in enumerate(self.client_datasets)]\n",
    "\n",
    "        if exist:\n",
    "            for client in self.clients:\n",
    "                client.load()\n",
    "            self.load()\n",
    "                \n",
    "    def train(self): \n",
    "        for client in self.clients:\n",
    "            client.run_training()\n",
    "\n",
    "    def test(self):\n",
    "        for client in self.clients:\n",
    "            predictions = client.pred()\n",
    "            client.check(predictions)\n",
    "            \n",
    "    def load(self):\n",
    "        from io import StringIO\n",
    "        result_path = f\"./results/ondevice/{self.data_config.DATASET_NAME}/{self.seed}/simulation.json\"\n",
    "        if os.path.isfile(result_path):\n",
    "            with open(result_path, 'r') as f:\n",
    "                results = json.load(f)\n",
    "    \n",
    "            self.results = results \n",
    "            for client_data in results['clients']:\n",
    "                idx = client_data['idx']\n",
    "                client = next((c for c in self.clients if c.idx == idx), None)\n",
    "                if client:\n",
    "                    client.cm = pd.read_json(StringIO(client_data['cm']), orient='split')\n",
    "                    client.train_losses = client_data['training_losses']\n",
    "                    client.test_losses = client_data['test_losses']\n",
    "                else:\n",
    "                    print(f\"[Warning] No client with idx={idx} found in self.clients.\")\n",
    "        \n",
    "    def to_json(self):\n",
    "        import json\n",
    "        simulation_data = {\n",
    "            \"configs\" : {\n",
    "                \"data\": self.data_config.__dict__(),\n",
    "                \"data_mode\" : self.data_mode.value,\n",
    "                \"transformation\": {\n",
    "                    \"transformation_type\": self.transform_type.value,\n",
    "                    \"transoformation_config\": self.transform_config.__dict__()\n",
    "                }\n",
    "            }\n",
    "\n",
    "        }\n",
    "        return json.dumps(simulation_data)\n",
    "\n",
    "    def collect_results(self, name: str, save: bool = True, figures: bool = False):\n",
    "        import json\n",
    "        import os\n",
    "        from IPython.display import display\n",
    "\n",
    "        self.results = {\n",
    "            'seed': name,\n",
    "            'clients': []\n",
    "        }\n",
    "\n",
    "        if figures:\n",
    "            fig = create_simulation_image_subplots(self)\n",
    "            display(fig)\n",
    "\n",
    "        for client in self.clients:\n",
    "            client_result = self._gather_client_results(client, figures)\n",
    "            self.results['clients'].append(client_result)\n",
    "\n",
    "        if save:\n",
    "            self._save_results(name)\n",
    "        return self.results\n",
    "\n",
    "    def _gather_client_results(self, client, figures):\n",
    "        result = {\n",
    "            'idx': client.idx,\n",
    "            'cm': client.cm.to_json(orient='split'),\n",
    "            'training_losses': client.train_losses,\n",
    "            'test_losses': client.test_losses\n",
    "        }\n",
    "\n",
    "        analysis, df_cm_per = cm_analysis(client)\n",
    "        result['cm_analysis'] = analysis\n",
    "\n",
    "        indices = [\n",
    "            analysis['correct']['most_correct_class'],\n",
    "            analysis['wrong']['most_misclassified_class']\n",
    "        ]\n",
    "        indices += [i for i in [analysis['wrong']['wrong_from'], analysis['wrong']['wrong_to']] if i not in indices]\n",
    "\n",
    "        # Performance metrics\n",
    "        result.update({\n",
    "            'accuracy': analysis[\"performance\"][\"accuracy\"],\n",
    "            'precision': analysis[\"performance\"][\"precision\"],\n",
    "            'recall': analysis[\"performance\"][\"recall\"]\n",
    "        })\n",
    "\n",
    "        # Generate and display figures if needed\n",
    "        if figures:\n",
    "            display(plot_test_loss(client.test_losses, 1, client.idx, \"Test\"))\n",
    "            fig, selected_indices = create_client_image_subplots(self, [client.idx], 8, keys=indices)\n",
    "            display(fig)\n",
    "            result['client_image_subplots_ids'] = selected_indices\n",
    "            display(print_cm_heat(df_cm_per, client.idx))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _save_results(self, name):\n",
    "        import os\n",
    "        import json\n",
    "\n",
    "        result_path = f\"./results/ondevice/{self.data_config.DATASET_NAME}/{name}\"\n",
    "        os.makedirs(result_path, exist_ok=True)\n",
    "        with open(os.path.join(result_path, \"simulation.json\"), \"w\") as f:\n",
    "            json.dump(self.results, f, indent=4)\n",
    "        print(\"Results saved to JSON.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a38cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in [1]:\n",
    "    data_config = DataConfiguration('MNIST')\n",
    "    transform_config = DataTransformConfiguration()\n",
    "    simulation = OnDeviceVerticalSimulation(data_config, transform_config, seed, OnDeviceMNISTModel, exist=False)\n",
    "    simulation.train()\n",
    "    #simulation.test()\n",
    "    #on_device_result = simulation.collect_results(seed, save = True, figures=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bba19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1869724a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
