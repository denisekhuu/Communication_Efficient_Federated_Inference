{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8734295-91c7-4050-9692-c5c0f19b40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e694e89-b9a1-4e0f-8407-cf8643031317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_inference.simulations.isolated.configs.data_config import DataConfiguration\n",
    "from federated_inference.simulations.isolated.configs.transform_config import DataTransformConfiguration\n",
    "from federated_inference.simulations.isolated.configs.model_config import ModelConfiguration\n",
    "from federated_inference.simulations.simulation import Simulation\n",
    "from federated_inference.simulations.isolated.models.IsolatedMnistModel import IsolatedMNISTModel\n",
    "from federated_inference.simulations.isolated.models.IsolatedFmnistModel import IsolatedFMNISTModel\n",
    "from federated_inference.simulations.isolated.simulation import IsolatedVerticalSimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ff761-633b-49d8-907e-2003c5edda11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_inference.simulations.naive.configs.data_config import DataConfiguration\n",
    "from federated_inference.simulations.naive.configs.transform_config import DataTransformConfiguration\n",
    "from federated_inference.simulations.naive.configs.model_config import ModelConfiguration\n",
    "from federated_inference.simulations.naive.models.NaiveMnistModel import NaiveMNISTModel\n",
    "from federated_inference.simulations.naive.models.NaiveFmnistModel import NaiveFMNISTModel\n",
    "from federated_inference.simulations.naive.simulation import NaiveVerticalSimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb686cc7-8348-493c-8cbc-d5b8ceafe007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import random \n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)                # CPU\n",
    "    torch.cuda.manual_seed(seed)           # Current GPU\n",
    "    torch.cuda.manual_seed_all(seed)       # All GPUs\n",
    "    np.random.seed(seed)                   # NumPy\n",
    "    random.seed(seed)                      # Python random\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f2020-42a6-4de0-8085-abdf301e3987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "naive_results = []\n",
    "isolated_results = []\n",
    "if __name__ == \"__main__\":\n",
    "    seeds = [3,4,5]\n",
    "    for seed in seeds:\n",
    "        set_seed(seed)\n",
    "        from federated_inference.simulations.isolated.configs.data_config import DataConfiguration\n",
    "        data_config = DataConfiguration('FMNIST')\n",
    "        transform_config = DataTransformConfiguration()\n",
    "        simulation = NaiveVerticalSimulation(seed, data_config, transform_config, NaiveFMNISTModel, exist = False)\n",
    "        simulation.train()\n",
    "        simulation.test_inference()\n",
    "        result = simulation.collect_results(seed, save = True)\n",
    "        naive_results.append(result)\n",
    "        from federated_inference.simulations.naive.configs.data_config import DataConfiguration\n",
    "        data_config = DataConfiguration('FMNIST')\n",
    "        simulation = IsolatedVerticalSimulation(data_config, transform_config, seed, IsolatedMNISTModel, exist=False)\n",
    "        simulation.train()\n",
    "        simulation.test()\n",
    "        result = simulation.collect_results(seed, save = True, figures=True)\n",
    "        isolated_results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adbce68-42ca-40f2-b0c2-8a72689d0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "class NaiveIsolatedExperiment():\n",
    "    def __init__(self):\n",
    "        self.isolated_results = []\n",
    "        self.naive_results = []\n",
    "    def _simulation_results(self, name = \"MNIST\", models =[NaiveMNISTModel, IsolatedMNISTModel]):  \n",
    "        seeds = [1,2,3,4,5]\n",
    "        self.name = name\n",
    "        for seed in seeds:\n",
    "            set_seed(seed)\n",
    "            from federated_inference.simulations.naive.configs.data_config import DataConfiguration\n",
    "            from federated_inference.simulations.naive.configs.transform_config import DataTransformConfiguration\n",
    "            data_config = DataConfiguration(name)\n",
    "            transform_config = DataTransformConfiguration()\n",
    "            simulation = NaiveVerticalSimulation(seed, data_config, transform_config, models[0], exist = True)\n",
    "            #simulation.train()\n",
    "            simulation.test_inference()\n",
    "            result = simulation.collect_results(seed, save = False)\n",
    "            self.naive_results.append(result)\n",
    "            from federated_inference.simulations.isolated.configs.data_config import DataConfiguration\n",
    "            from federated_inference.simulations.isolated.configs.transform_config import DataTransformConfiguration\n",
    "            data_config = DataConfiguration(name)\n",
    "            simulation = IsolatedVerticalSimulation(data_config, transform_config, seed, models[1], exist=True)\n",
    "            #simulation.train()\n",
    "            simulation.test()\n",
    "            result = simulation.collect_results(seed, save = False, figures=False)\n",
    "            self.isolated_results.append(result)\n",
    "\n",
    "    def _precision_recall(self, idx):\n",
    "        import numpy as np\n",
    "        values = [r['client'][0]['precision'][idx] for r in self.naive_results]\n",
    "        mean =  np.mean(values)\n",
    "        var = np.var(values)\n",
    "        var1 = (mean, var)\n",
    "        var2 = []\n",
    "        for i in range(len(self.isolated_results[0]['clients'])):\n",
    "            values = [r['clients'][i]['precision'][idx] for r in self.isolated_results]\n",
    "            mean =  np.mean(values)\n",
    "            var = np.var(values)\n",
    "            var2.append((mean, var))\n",
    "        var4 = []\n",
    "        values = [r['client'][0]['recall'][idx] for r in self.naive_results]\n",
    "        mean =  np.mean(values)\n",
    "        var = np.var(values)\n",
    "        var3 = (mean, var)\n",
    "        for i in range(len(self.isolated_results[0]['clients'])):\n",
    "            values = [r['clients'][i]['recall'][idx] for r in self.isolated_results]\n",
    "            mean =  np.mean(values)\n",
    "            var = np.var(values)\n",
    "            var4.append((mean, var))\n",
    "        return var1, var2, var3, var4\n",
    "\n",
    "    def __precision_recall_fig(self, name, idx):\n",
    "        import plotly.graph_objects as go\n",
    "        var1, var2, var3, var4 = self._precision_recall(idx)\n",
    "        # Labels for x-axis\n",
    "        labels = [\"Naive Server\"] + [f\"Isolated Client {i}\" for i in range(len(var2))]\n",
    "        \n",
    "        # Build traces\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Precision trace\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=labels,\n",
    "            y=[var1[0]] + [v[0] for v in var2],\n",
    "            name='Precision',\n",
    "            marker_color='steelblue',\n",
    "            error_y=dict(\n",
    "                type='data',\n",
    "                array=[var1[1]**0.5] + [v[1]**0.5 for v in var2],\n",
    "                visible=True\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        # Recall trace\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=labels,\n",
    "            y=[var3[0]] + [v[0] for v in var4],\n",
    "            name='Recall',\n",
    "            marker_color='darkorange',\n",
    "            error_y=dict(\n",
    "                type='data',\n",
    "                array=[var3[1]**0.5] + [v[1]**0.5 for v in var4],\n",
    "                visible=True\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        # Layout\n",
    "        fig.update_layout(\n",
    "            title=f\"{name} Precision and Recall of Class {idx}\",\n",
    "            xaxis_title='Experiment',\n",
    "            yaxis_title='Score',\n",
    "            yaxis=dict(range=[0.2, 1.0]),\n",
    "            barmode='group',\n",
    "            template='plotly_white'\n",
    "        \n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "\n",
    "    def show_recall_figs(self):\n",
    "        for i in range(10):\n",
    "            self.__precision_recall_fig(self.name,i)\n",
    "\n",
    "    \n",
    "    def _accuracy(self):\n",
    "        import numpy as np\n",
    "        \n",
    "        values = [r['client'][0]['accuracy'] for r in self.naive_results]\n",
    "        mean =  np.mean(values)\n",
    "        var = np.var(values)\n",
    "        var1 = (mean, var)\n",
    "        \n",
    "        var2 = []\n",
    "        for i in range(len(self.isolated_results[0]['clients'])):\n",
    "            values = [r['clients'][i]['accuracy'] for r in self.isolated_results]\n",
    "            mean =  np.mean(values)\n",
    "            var = np.var(values)\n",
    "            var2.append((mean, var))\n",
    "        return var1, var2\n",
    "    \n",
    "    def _accuracy_comparison(): \n",
    "        var1, var2 = self._accuracy()\n",
    "        \n",
    "        import plotly.graph_objects as go\n",
    "        results = [(\"Naive Server\", var1[0], var1[1])] + [(f\"Isolated Client {i}\", acc, var) for i, (acc, var) in enumerate(var2)]\n",
    "        \n",
    "        labels = [r[0] for r in results]\n",
    "        accuracies = [r[1] for r in results]\n",
    "        variances = [r[2] for r in results]\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_trace(go.Bar(\n",
    "            x=labels,\n",
    "            y=accuracies,\n",
    "            name='Accuracy',\n",
    "            marker_color='steelblue',\n",
    "            error_y=dict(\n",
    "                type='data',\n",
    "                array=[v ** 0.5 for v in variances],  # Use stddev for error bars\n",
    "                visible=True\n",
    "            )\n",
    "        ))\n",
    "        s\n",
    "        # Customize layout\n",
    "        fig.update_layout(\n",
    "            title=f\"{self.name} Accuracy\",\n",
    "            xaxis_title='Experiment',\n",
    "            yaxis_title='Accuracy',\n",
    "            yaxis=dict(range=[0.7, 1.0]),\n",
    "            template='plotly_white'\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "\n",
    "ex = NaiveIsolatedExperiment()\n",
    "ex._simulation_results()\n",
    "ex.show_recall_figs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bf842f-c130-4b73-bac6-edd2ceaef44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex._simulation_results(\"FMNIST\", [NaiveFMNISTModel, IsolatedFMNISTModel])\n",
    "ex.show_recall_figs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a141c2db-9289-44be-8c08-6a5388e83cdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def pred(self):\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    confidence_corrects = []\n",
    "    testset = self.data.test_dataset\n",
    "    testloader = self._pred_loader(testset, self.model_config.BATCH_SIZE_TEST, self.model_config.TEST_SHUFFLE)\n",
    "    self.model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader :\n",
    "            data = data.to(self.model_config.DEVICE).float()\n",
    "            target = target.to(self.model_config.DEVICE).long()\n",
    "            output = self.model(data)\n",
    "            probs = F.softmax(output, dim=1)\n",
    "            confidence, _ = probs.max(dim=1, keepdim=True)\n",
    "            confidence_true = probs[torch.arange(len(target)), target]\n",
    "            confidences += confidence.squeeze().tolist()\n",
    "            confidence_corrects += confidence_true.squeeze().tolist()\n",
    "            test_loss += self.criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            predictions = predictions + pred.squeeze().tolist()\n",
    "\n",
    "    return confidences, confidence_corrects, predictions\n",
    "\n",
    "\n",
    "for client in simulation.clients:\n",
    "    \n",
    "    confidences, confidences_trues, predictions = pred(client)\n",
    "    true_labels = client.data.test_dataset.targets.squeeze().tolist()\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'target': list(true_labels),\n",
    "        'confidence': confidences,\n",
    "        'confidence_correct': confidences_trues,\n",
    "        'predictions': predictions,\n",
    "    })\n",
    "\n",
    "    df = df[df['target'] == df['predictions']]\n",
    "    \n",
    "    # Group by target and calculate mean and variance\n",
    "    summary = df.groupby('target')['confidence'].agg(['mean', 'var']).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity (optional)\n",
    "    summary.columns = ['target', 'avg_max_confidence', 'variance']\n",
    "    \n",
    "    print(summary)\n",
    "\n",
    "    summary = df.groupby('target')['confidence_correct'].agg(['mean', 'var']).reset_index()\n",
    "    print(summary)\n",
    "\n",
    "    print(\"_\"*40)\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'target': list(true_labels),\n",
    "        'confidence': confidences,\n",
    "        'confidence_correct': confidences_trues,\n",
    "        'predictions': predictions,\n",
    "    })\n",
    "\n",
    "    df = df[df['target'] != df['predictions']]\n",
    "\n",
    "    # Group by target and calculate mean and variance\n",
    "    summary = df.groupby('target')['confidence'].agg(['mean', 'var']).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity (optional)\n",
    "    summary.columns = ['target', 'avg_max_confidence', 'variance']\n",
    "    \n",
    "    print(summary)\n",
    "\n",
    "    summary = df.groupby('target')['confidence_correct'].agg(['mean', 'var']).reset_index()\n",
    "    print(summary)\n",
    "    print(\"_\"*40)\n",
    "    print(\"_\"*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806738e-cfac-4159-aafd-f5fde99e0511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Create full DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'target': list(true_labels),\n",
    "    'confidence': confidences,\n",
    "    'confidence_correct': confidences_trues,\n",
    "    'predictions': predictions,\n",
    "})\n",
    "\n",
    "# Split correct and incorrect\n",
    "df_correct = df[df['target'] == df['predictions']]\n",
    "df_wrong = df[df['target'] != df['predictions']]\n",
    "\n",
    "# Function to summarize a group\n",
    "def summarize_group(df_sub, label):\n",
    "    conf_summary = df_sub.groupby('target')['confidence'].agg(['mean', 'var']).rename(columns={'mean': f'{label}_avg_max_conf', 'var': f'{label}_var_max_conf'})\n",
    "    conf_true_summary = df_sub.groupby('target')['confidence_correct'].agg(['mean', 'var']).rename(columns={'mean': f'{label}_avg_true_conf', 'var': f'{label}_var_true_conf'})\n",
    "    return conf_summary.join(conf_true_summary, how='outer')\n",
    "\n",
    "# Summarize correct and wrong separately\n",
    "summary_correct = summarize_group(df_correct, 'correct')\n",
    "summary_wrong = summarize_group(df_wrong, 'wrong')\n",
    "\n",
    "# Compute precision and recall\n",
    "precision, recall, _, _ = precision_recall_fscore_support(true_labels, predictions, labels=sorted(set(true_labels)), zero_division=0)\n",
    "metrics_df = pd.DataFrame({\n",
    "    'target': sorted(set(true_labels)),\n",
    "    'precision': precision,\n",
    "    'recall': recall\n",
    "})\n",
    "\n",
    "# Combine everything\n",
    "final_summary = metrics_df.set_index('target') \\\n",
    "    .join(summary_correct, how='left') \\\n",
    "    .join(summary_wrong, how='left') \\\n",
    "    .reset_index()\n",
    "\n",
    "# Fill NaNs for classes that may have no correct/wrong predictions\n",
    "final_summary = final_summary.fillna(0)\n",
    "\n",
    "# Display result\n",
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c542809c-5341-422c-940b-ecd24dee125a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "    # Stack batches into full dataset arrays\n",
    "    features_tensor = torch.cat(all_features)  # shape: [N, 784]\n",
    "    labels_tensor = torch.cat(all_labels)\n",
    "\n",
    "\n",
    "    # Convert tensors to NumPy arrays\n",
    "    features_np = features_tensor.numpy()\n",
    "    labels_np = labels_tensor.numpy()\n",
    "    \n",
    "    # Filter for two specific digits (e.g., 3 and 8)\n",
    "    target_digits = [1, 0]\n",
    "    mask = np.isin(labels_np, target_digits)\n",
    "    features_np = features_np[mask]\n",
    "    labels_np = labels_np[mask]\n",
    "\n",
    "    sample_size = 5000\n",
    "    # If dataset is larger than sample_size, randomly sample without replacement for faster PCA\n",
    "    if features_np.shape[0] > sample_size:\n",
    "        rng = np.random.default_rng(seed=42)  # Use a fixed seed for reproducibility\n",
    "        idx = rng.choice(features_np.shape[0], size=sample_size, replace=False)\n",
    "        features_np = features_np[idx]\n",
    "        labels_np = labels_np[idx]\n",
    "\n",
    "    # Apply PCA to reduce features to 2 dimensions\n",
    "    pca = PCA(n_components=2)\n",
    "    features_pca = pca.fit_transform(features_np)\n",
    "\n",
    "    # Plot the 2D PCA embedding, color-coded by digit label\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for digit in range(10):\n",
    "        idxs = labels_np == digit\n",
    "        plt.scatter(features_pca[idxs, 0], features_pca[idxs, 1], label=str(digit), alpha=0.5, s=20)\n",
    "\n",
    "    plt.title('PCA of CNN Features for All MNIST Digits')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend(title='Digit')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a885341-361a-4bee-9333-df8beb08fb40",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.decomposition import PCA\n",
    "    client = simulation.clients[0] \n",
    "    client.model.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in client.trainloader:\n",
    "            images = images.to(model_config.DEVICE)\n",
    "            features = client.model.features(images)\n",
    "            features = torch.flatten(features, start_dim=1) \n",
    "            all_features.append(features.cpu())\n",
    "            all_labels.append(labels)\n",
    "\n",
    "\n",
    "    # Stack batches into full dataset arrays\n",
    "    features_tensor = torch.cat(all_features)  # shape: [N, 784]\n",
    "    labels_tensor = torch.cat(all_labels)\n",
    "\n",
    "\n",
    "    # Convert tensors to NumPy arrays\n",
    "    features_np = features_tensor.numpy()\n",
    "    labels_np = labels_tensor.numpy()\n",
    "\n",
    "    sample_size = 5000\n",
    "    # If dataset is larger than sample_size, randomly sample without replacement for faster PCA\n",
    "    if features_np.shape[0] > sample_size:\n",
    "        rng = np.random.default_rng(seed=42)  # Use a fixed seed for reproducibility\n",
    "        idx = rng.choice(features_np.shape[0], size=sample_size, replace=False)\n",
    "        features_np = features_np[idx]\n",
    "        labels_np = labels_np[idx]\n",
    "\n",
    "    # Apply PCA to reduce features to 2 dimensions\n",
    "    pca = PCA(n_components=3)\n",
    "    features_pca = pca.fit_transform(features_np)\n",
    "\n",
    "    # Plot the 2D PCA embedding, color-coded by digit label\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for digit in target_digits:\n",
    "        idxs = labels_np == digit\n",
    "        plt.scatter(features_pca[idxs, 0], features_pca[idxs, 1], label=str(digit), alpha=0.5, s=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b537ae0c-f7c6-4343-84e1-8d8c5d7d89f2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.decomposition import PCA\n",
    "    client = simulation.clients[0] \n",
    "    client.model.eval()\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in client.trainloader:\n",
    "            images = images.to(model_config.DEVICE)\n",
    "            features = client.model.features(images)\n",
    "            features = torch.flatten(features, start_dim=1) \n",
    "            all_features.append(features.cpu())\n",
    "            all_labels.append(labels)\n",
    "\n",
    "\n",
    "    # Stack batches into full dataset arrays\n",
    "    features_tensor = torch.cat(all_features)  # shape: [N, 784]\n",
    "    labels_tensor = torch.cat(all_labels)\n",
    "\n",
    "\n",
    "    # Convert tensors to NumPy arrays\n",
    "    features_np = features_tensor.numpy()\n",
    "    labels_np = labels_tensor.numpy()\n",
    "    \n",
    "    # Filter for two specific digits (e.g., 3 and 8)\n",
    "    target_digits = [0,1]\n",
    "    mask = np.isin(labels_np, target_digits)\n",
    "    features_np = features_np[mask]\n",
    "    labels_np = labels_np[mask]\n",
    "\n",
    "    sample_size = 5000\n",
    "    # If dataset is larger than sample_size, randomly sample without replacement for faster PCA\n",
    "    if features_np.shape[0] > sample_size:\n",
    "        rng = np.random.default_rng(seed=42)  # Use a fixed seed for reproducibility\n",
    "        idx = rng.choice(features_np.shape[0], size=sample_size, replace=False)\n",
    "        features_np = features_np[idx]\n",
    "        labels_np = labels_np[idx]\n",
    "\n",
    "    # Apply PCA to reduce features to 2 dimensions\n",
    "    pca = PCA(n_components=3)\n",
    "    features_pca = pca.fit_transform(features_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802093e3-54c2-4e0e-9f7c-74007fab4a41",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def tensor_to_numpy_image(tensor_img):\n",
    "    \"\"\"\n",
    "    Convert a torch Tensor image to numpy array suitable for plotly.\n",
    "    Assumes image shape is [C, H, W], returns [H, W, C].\n",
    "    \"\"\"\n",
    "    if isinstance(tensor_img, torch.Tensor):\n",
    "        img = tensor_img.detach().cpu().numpy()\n",
    "        if img.ndim == 3:  # C,H,W -> H,W,C\n",
    "            img = np.transpose(img, (1, 2, 0))\n",
    "        # If grayscale (1 channel), squeeze channel dim\n",
    "        if img.shape[-1] == 1:\n",
    "            img = img.squeeze(-1)\n",
    "        # Normalize to [0,255] uint8 if float\n",
    "        if img.dtype != np.uint8:\n",
    "            img = (img * 255).clip(0, 255).astype(np.uint8)\n",
    "        return img\n",
    "    else:\n",
    "        # Assume already numpy image\n",
    "        return tensor_img\n",
    "\n",
    "def create_clients_image_subplots(datasets, n_images=3):\n",
    "    \"\"\"\n",
    "    Create a Plotly figure with one row per client dataset,\n",
    "    showing `n_images` images per client side-by-side.\n",
    "\n",
    "    Parameters:\n",
    "    - datasets: list of torch.utils.data.Dataset (one per client)\n",
    "    - n_images: how many images to show per client (default 3)\n",
    "    \"\"\"\n",
    "    n_clients = len(datasets)\n",
    "    fig = sp.make_subplots(rows=n_clients, cols=n_images,\n",
    "                           subplot_titles=[f\"Img {i+1}\" for i in range(n_images)],\n",
    "                           vertical_spacing=0.05,\n",
    "                           horizontal_spacing=0.01)\n",
    "\n",
    "    for r, dataset in enumerate(datasets, start=1):\n",
    "        # Pick n_images images from dataset\n",
    "        for c in range(n_images):\n",
    "            if c >= len(dataset):\n",
    "                break\n",
    "            img, label = dataset[c]\n",
    "            img_np = tensor_to_numpy_image(img)\n",
    "\n",
    "            fig.add_trace(go.Image(z=img_np), row=r, col=c+1)\n",
    "\n",
    "        # Set y-axis title as Client number (only once per row)\n",
    "        fig.update_yaxes(title_text=f\"Client {r}\", row=r, col=1)\n",
    "\n",
    "    fig.update_layout(height=250 * n_clients, width=250 * n_images,\n",
    "                      showlegend=False, title_text=\"Clients Dataset Images\")\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f55d2-d55e-4825-b422-09fd83aa9e65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame for Plotly\n",
    "df = pd.DataFrame({\n",
    "    'PC1': features_pca[:, 0],\n",
    "    'PC2': features_pca[:, 1],\n",
    "    'PC3': features_pca[:, 2],\n",
    "    'Digit': labels_np.astype(str)  # convert labels to strings for grouping\n",
    "})\n",
    "\n",
    "# Create interactive 3D scatter plot\n",
    "fig = px.scatter_3d(\n",
    "    df,\n",
    "    x='PC1', y='PC2', z='PC3',\n",
    "    color='Digit',\n",
    "    title='3D PCA of CNN Features for Digits 1, 2, and 3',\n",
    "    opacity=0.7,\n",
    "    symbol='Digit'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend_title_text='Digit',\n",
    "    margin=dict(l=0, r=0, b=0, t=40),\n",
    "    scene=dict(\n",
    "        xaxis_title='PC 1',\n",
    "        yaxis_title='PC 2',\n",
    "        zaxis_title='PC 3'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb69f35a-6899-4883-af37-648a1c6650d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
