{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39555cae-7d7d-45e8-aa49-b7c774aba30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04fdd78-aba2-42f1-a08f-6e5009db2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random \n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)                # CPU\n",
    "    torch.cuda.manual_seed(seed)           # Current GPU\n",
    "    torch.cuda.manual_seed_all(seed)       # All GPUs\n",
    "    np.random.seed(seed)                   # NumPy\n",
    "    random.seed(seed)                      # Python random\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c435a4-ff6a-4be9-b491-554fc88f24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class IGV1Base(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return x\n",
    "\n",
    "class IGV1ClassifierHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(500, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "class InformationGateV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(500, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "class SplitServerCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2000, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(50, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_concat):\n",
    "        return self.classifier(x_concat)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3a1b4-0530-4d60-9da5-aa2f147a7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from federated_inference.dataset import MNISTDataset, FMNISTDataset, CIFAR10Dataset\n",
    "from federated_inference.common.environment import DataSetEnum\n",
    "\n",
    "class DataConfiguration():\n",
    "    \n",
    "    #MNIST_FASHION_DATASET Configurations\n",
    "    FMNIST_NAME = 'FMNIST'\n",
    "    FMNIST_DATASET_PATH = os.path.join('./data/fmnist')\n",
    "    FMNIST_LABELS = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker',  'Bag', 'Ankle Boot']\n",
    "    \n",
    "    #MNIST_DATASET Configurations\n",
    "    MNIST_NAME = 'MNIST'\n",
    "    MNIST_DATASET_PATH = os.path.join('./data/mnist')\n",
    "    \n",
    "    #CIFAR_DATASET Configurations\n",
    "    CIFAR10_NAME = 'CIFAR10'\n",
    "    CIFAR10_DATASET_PATH = os.path.join('./data/cifar10')\n",
    "    CIFAR10_LABELS = ['Plane', 'Car', 'Bird', 'Cat','Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "\n",
    "    def __init__(self, dataset_name : str = None):\n",
    "        load_dotenv(override=True)\n",
    "        self.DATASET_NAME = dataset_name if dataset_name else os.getenv('DATASET_NAME', 'MNIST')\n",
    "        if self.DATASET_NAME == DataSetEnum.MNIST.value: \n",
    "            self.INSTANCE_SIZE = (1, 28, 28)\n",
    "            self.DATASET = DataSetEnum.MNIST\n",
    "            self.DATASET_PATH = os.path.join(os.getenv('DATASET_PATH', self.MNIST_DATASET_PATH))\n",
    "            self.LABELS = range(10)\n",
    "        if self.DATASET_NAME == DataSetEnum.FMNIST.value: \n",
    "            self.INSTANCE_SIZE = (1, 28, 28)\n",
    "            self.DATASET = DataSetEnum.FMNIST\n",
    "            self.DATASET_PATH = os.path.join(os.getenv('DATASET_PATH', self.FMNIST_DATASET_PATH))\n",
    "            self.LABELS = self.FMNIST_LABELS\n",
    "        if self.DATASET_NAME == DataSetEnum.CIFAR10.value:\n",
    "            self.INSTANCE_SIZE = (1, 32, 32)\n",
    "            self.DATASET = DataSetEnum.CIFAR10\n",
    "            self.DATASET_PATH = os.path.join(os.getenv('DATASET_PATH', self.CIFAR10_DATASET_PATH))\n",
    "            self.LABELS =  self.CIFAR10_LABELS\n",
    "\n",
    "    def __dict__(self):\n",
    "        return {\n",
    "            \"dataset_name\": self.DATASET_NAME, \n",
    "            \"labels\": list(self.LABELS),\n",
    "            \"size\": self.INSTANCE_SIZE\n",
    "        }\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "class ModelConfiguration():\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                          else \"mps\" if torch.backends.mps.is_available()\n",
    "                          else \"cpu\")\n",
    "\n",
    "    def __init__(self,  \n",
    "        server_model: nn.Module, \n",
    "        client_base_model: nn.Module, \n",
    "        client_classifier_head: nn.Module, \n",
    "        client_ig_head: nn.Module,          \n",
    "        learning_rate: float = 0.001, \n",
    "        batch_size_train: int = 64, \n",
    "        batch_size_val: int = 64, \n",
    "        batch_size_test: int = 64, \n",
    "        train_shuffle: bool = False, \n",
    "        val_shuffle: bool = False, \n",
    "        test_suffle: bool = False, \n",
    "        n_epochs: int = 30,\n",
    "        train_ratio: float = 0.8):\n",
    "        self.SERVER_MODEL = server_model\n",
    "        self.CLIENT_BASE_MODEL = client_base_model\n",
    "        self.CLIENT_CLASSIFIER_MODEL = client_classifier_head\n",
    "        self.CLIENT_IG_MODEL = client_ig_head\n",
    "        self.LEARNING_RATE = learning_rate\n",
    "        self.TRAIN_RATIO = train_ratio\n",
    "        self.BATCH_SIZE_TRAIN = batch_size_train\n",
    "        self.BATCH_SIZE_VAL = batch_size_val\n",
    "        self.BATCH_SIZE_TEST = batch_size_test\n",
    "        self.TRAIN_SHUFFLE = train_shuffle\n",
    "        self.VAL_SHUFFLE = val_shuffle\n",
    "        self.TEST_SHUFFLE = test_suffle\n",
    "        self.N_EPOCH = n_epochs\n",
    "\n",
    "    def __dict__(self):\n",
    "        return {\n",
    "            \"learning_rate\": self.LEARNING_RATE, \n",
    "            \"train_ratio\": self.TRAIN_RATIO,\n",
    "            \"batch_size_train\": self.BATCH_SIZE_TRAIN,\n",
    "            \"batch_size_val\": self.BATCH_SIZE_VAL,\n",
    "            \"batch_size_test\": self.BATCH_SIZE_TEST, \n",
    "            \"train_shuffle\": self.TRAIN_SHUFFLE,\n",
    "            \"val_shuffle\": self.VAL_SHUFFLE,\n",
    "            \"test_shuffle\": self.TEST_SHUFFLE,\n",
    "            \"n_epoch\": self.N_EPOCH, \n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96bd6be-905d-45a6-ba7c-2443429397bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from federated_inference.common.cost_calculator import CostCalculator\n",
    "from federated_inference.common.environment import Member\n",
    "from collections.abc import Iterable\n",
    "import logging \n",
    "\n",
    "class IGV1Client():\n",
    "\n",
    "    def __init__(self, \n",
    "            idx, \n",
    "            data_config: DataConfiguration,\n",
    "            dataset: TorchDataset,\n",
    "            labels,\n",
    "            log: bool = True, \n",
    "            log_interval: int = 100, \n",
    "            save_interval: int = 20\n",
    "        ):\n",
    "        self.idx = idx\n",
    "        self.seed = seed\n",
    "        self.data = dataset\n",
    "        self.data_config = data_config\n",
    "        self.labels = labels\n",
    "        self.numerical_labels = range(len(labels))\n",
    "        self.member_type = Member.CLIENT\n",
    "        self.model = None\n",
    "        self.costs = []\n",
    "\n",
    "        self.log = log\n",
    "        self.log_interval = log_interval\n",
    "        self.save_interval = save_interval\n",
    "\n",
    "    def select_subset(self, ids: Iterable[int], set_type: str = \"train\"):\n",
    "        if set_type == \"test\":\n",
    "            return Subset(self.data.test_dataset, ids)\n",
    "        else: \n",
    "            return Subset(self.data.train_dataset, ids)\n",
    "\n",
    "    def send_all(self):\n",
    "        cost = CostCalculator.calculate_communication_cost_by(self.data.train_dataset)\n",
    "        cost.set_cost_reason(\"send_all_training\")\n",
    "        self.costs.append(cost)\n",
    "        return self.data.train_dataset\n",
    "\n",
    "    def request_pred(self, idx: int|None = None, set_type: str = \"test\", pred_all: bool= False, keep_label: bool = False): \n",
    "        if idx != None:\n",
    "            if set_type == \"test\":\n",
    "                data = self.data.test_dataset[idx]\n",
    "                cost = CostCalculator.calculate_communication_cost_by(data)\n",
    "                cost.set_cost_reason(\"send_testing_pred_request\")\n",
    "                self.costs.append(cost)\n",
    "                \n",
    "                return self.data.test_dataset[idx] if keep_label else self.data.test_dataset[idx][0] \n",
    "        elif pred_all:\n",
    "            cost = CostCalculator.calculate_communication_cost_by(self.data.test_dataset)\n",
    "            cost.set_cost_reason(\"send_all_testing_pred_request\")\n",
    "            self.costs.append(cost)\n",
    "            return self.data.test_dataset if keep_label else [img for img, label in self.data.test_dataset]\n",
    "\n",
    "    def check(self, predicted_labels,  pred_all: bool= True):\n",
    "        from sklearn.metrics import accuracy_score, precision_score, recall_score,  confusion_matrix\n",
    "        import pandas as pd\n",
    "        if pred_all:\n",
    "            true_labels = self.data.test_dataset.targets\n",
    "            accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "            precision = precision_score(true_labels, predicted_labels, average='macro')  # or 'weighted'\n",
    "            recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "            print(\"\\n=== Metrics ===\")\n",
    "            print(f\"Accuracy : {accuracy:.4f}\")\n",
    "            print(f\"Precision: {precision:.4f}\")\n",
    "            print(f\"Recall   : {recall:.4f}\")\n",
    "            cm = confusion_matrix(self.data.test_dataset.targets, predicted_labels, labels=self.numerical_labels)\n",
    "            self.cm = pd.DataFrame(cm, index=[f'True {l}' for l in self.labels],\n",
    "                                    columns=[f'Pred {l}' for l in self.labels])\n",
    "            self.accuracy = accuracy \n",
    "            self.precision = precision \n",
    "            self.recall = recall\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from federated_inference.common.cost_calculator import CostCalculator\n",
    "from federated_inference.common.environment import Member\n",
    "from collections.abc import Iterable\n",
    "import logging \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from collections.abc import Iterable\n",
    "import os\n",
    "\n",
    "class EarlyStopper():\n",
    "    def __init__(self, patience = 5, min_delta = 0.00001):\n",
    "        self.patience = patience \n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0 \n",
    "        self.best_loss = None \n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None: \n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else: \n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        \n",
    "\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from federated_inference.common.cost_calculator import CostCalculator\n",
    "from federated_inference.common.environment import Member\n",
    "from collections.abc import Iterable\n",
    "import logging \n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from collections.abc import Iterable\n",
    "import os\n",
    "class IGV1Server():\n",
    "\n",
    "    def __init__(self, \n",
    "            idx, \n",
    "            seed,\n",
    "            model_config: ModelConfiguration,\n",
    "            data_config: DataConfiguration,\n",
    "            log: bool = True, \n",
    "            log_interval: int = 100,\n",
    "            save_interval: int = 20\n",
    "        ):\n",
    "        self.idx = idx\n",
    "        self.seed = seed\n",
    "        self.model_config = model_config\n",
    "        self.data_config = data_config\n",
    "        self.seed = seed\n",
    "        self.number_of_clients = 4\n",
    "        self.n_epoch = model_config.N_EPOCH\n",
    "        self.device = model_config.DEVICE\n",
    "        self.member_type = Member.SERVER\n",
    "        self.server_model = model_config.SERVER_MODEL().to(self.device)\n",
    "        self.client_base_models = [model_config.CLIENT_BASE_MODEL().to(self.device) for c in range(self.number_of_clients)]\n",
    "        self.client_classifier_models = [model_config.CLIENT_CLASSIFIER_MODEL().to(self.device) for c in range(self.number_of_clients)]\n",
    "        self.client_ig_models = [model_config.CLIENT_IG_MODEL().to(self.device) for c in range(self.number_of_clients)]\n",
    "        self.CRITERION = nn.CrossEntropyLoss()\n",
    "        self.CRITERION_NAME = \"CrossEntropyLoss\"\n",
    "        self.SERVER_OPTIMIZER = optim.Adam(self.server_model.parameters() , lr=model_config.LEARNING_RATE)\n",
    "        self.CLIENT_BASE_OPTIMIZERS =  [optim.Adam(self.client_base_models[c].parameters() , lr=model_config.LEARNING_RATE) for c in range(self.number_of_clients)]\n",
    "        self.CLIENT_CLASSIFIER_OPTIMIZERS =  [optim.Adam(self.client_classifier_models[c].parameters() , lr=model_config.LEARNING_RATE) for c in range(self.number_of_clients)]\n",
    "        self.CLIENT_IG_OPTIMIZERS =  [optim.Adam(self.client_ig_models[c].parameters() , lr=model_config.LEARNING_RATE) for c in range(self.number_of_clients)]\n",
    "        self.OPTIMIZER_NAME = \"Adam\"\n",
    "        self.LOCAL_CLASSIFIER_CRITERION = nn.CrossEntropyLoss()\n",
    "        self.LOCAL_IG_CRITERION = nn.BCELoss()\n",
    "        self.costs = []\n",
    "\n",
    "        self.log = log\n",
    "        self.log_interval = log_interval\n",
    "        self.save_interval = save_interval\n",
    "\n",
    "        if self.log: \n",
    "            self.train_losses = []\n",
    "            self.test_losses = []\n",
    "            self.accuracies = []\n",
    "\n",
    "\n",
    "    def _to_loader(self, trainsets, testsets, batch_size_train, batch_size_val, batch_size_test, train_shuffle, val_shuffle, test_shuffle, train_ratio):\n",
    "        # TODO refactoing to use self\n",
    "        if train_shuffle:\n",
    "            dataset_length = len(trainsets[0])\n",
    "            assert all(len(trainset) == dataset_length for trainset in trainsets), \"All trainsets must be the same length\"\n",
    "\n",
    "            indices = np.arange(dataset_length)\n",
    "\n",
    "            if train_shuffle:\n",
    "                np.random.shuffle(indices)\n",
    "\n",
    "            train_end = round(train_ratio * dataset_length)\n",
    "            train_indices = indices[:train_end]\n",
    "            val_indices = indices[train_end:]\n",
    "\n",
    "            traindatas = [Subset(trainset, train_indices) for trainset in trainsets]\n",
    "            valdatas = [Subset(trainset, val_indices) for trainset in trainsets]\n",
    "        else:\n",
    "            traindatas = [Subset(trainset, range(round(train_ratio*len(trainset)))) for trainset in trainsets]\n",
    "            valdatas = [Subset(trainset, range(round(train_ratio*len(trainset)), len(trainset))) for trainset in trainsets]\n",
    "        self.trainloader = [DataLoader(traindata, batch_size=batch_size_train, shuffle=False)  for traindata in traindatas]\n",
    "        self.valloader = [DataLoader(valdata, batch_size=batch_size_val, shuffle=False) for valdata in valdatas]\n",
    "        self.testloader = [DataLoader(testdata, batch_size=batch_size_test, shuffle=False) for testdata in testsets]\n",
    "\n",
    "\n",
    "    def _pred_loader(self, testsets, batch_size_test, test_shuffle):\n",
    "        return  [DataLoader(testdata, batch_size=batch_size_test, shuffle=False) for testdata in testsets]\n",
    "\n",
    "\n",
    "    def train(self, epoch):\n",
    "        for batch_idx, batches in enumerate(zip(*self.trainloader)):\n",
    "            # batches is tuple of batch from each loader\n",
    "            data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "            target = batches[0][1].to(self.device).long()\n",
    "\n",
    "            # Client FeedForward\n",
    "            client_activations = []\n",
    "            for data, client_model in zip(data_slices, self.client_base_models):\n",
    "                client_model.train()\n",
    "                activation = client_model(data)\n",
    "                activation.requires_grad_()\n",
    "                client_activations.append(activation)\n",
    "\n",
    "            concat_activations = torch.cat(client_activations, dim=1)\n",
    "            \n",
    "            #Server FeedForward\n",
    "            self.server_model.train()\n",
    "            self.SERVER_OPTIMIZER.zero_grad()\n",
    "            output = self.server_model(concat_activations)\n",
    "            loss =  self.CRITERION(output, target)\n",
    "            if self.log: \n",
    "                self.train_losses.append(loss.item())\n",
    "            # Get gradients for both activation and model parameters\n",
    "            grads = torch.autograd.grad(loss, [concat_activations] + list(self.server_model.parameters()))\n",
    "\n",
    "            #Server Backprop\n",
    "            concat_activation_grad = grads[0]\n",
    "            model_grads = grads[1:]\n",
    "            # Apply gradients manually to model parameters\n",
    "            for param, grad in zip(self.server_model.parameters(), model_grads):\n",
    "                param.grad = grad  # Set .grad for optimizer\n",
    "\n",
    "            self.SERVER_OPTIMIZER.step()\n",
    "\n",
    "            # Client Backprop  \n",
    "            activation_sizes = [act.shape[1] for act in client_activations]\n",
    "            activation_grads = torch.split(concat_activation_grad, activation_sizes, dim=1)\n",
    "\n",
    "            for i, activation_grad in enumerate(activation_grads):\n",
    "                self.client_base_models[i].train()\n",
    "                self.CLIENT_BASE_OPTIMIZERS[i].zero_grad()\n",
    "                activation =  self.client_base_models[i](data)\n",
    "                activation.backward(activation_grad)\n",
    "                self.CLIENT_BASE_OPTIMIZERS[i].step()\n",
    "                \n",
    "            if self.log and batch_idx % self.log_interval == 0:\n",
    "                print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(self.trainloader[0].dataset)} '\n",
    "                    f'({100. * batch_idx / len(self.trainloader[0]):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "            if batch_idx % self.save_interval == 0:\n",
    "                self.train_losses.append(loss.item())\n",
    "                \n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batches in enumerate(zip(*self.valloader)):\n",
    "                data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "                target = batches[0][1].to(self.device).long()\n",
    "                client_activations = []\n",
    "                for data, client_model in zip(data_slices, self.client_base_models):\n",
    "                    #Client FeedForward\n",
    "                    client_model.eval()\n",
    "                    activation = client_model(data)\n",
    "                    client_activations.append(activation)\n",
    "                concat_activations = torch.cat(client_activations, dim=1)\n",
    "                #Server FeedForward\n",
    "                self.server_model.eval()\n",
    "                output = self.server_model(concat_activations)\n",
    "                val_loss +=  self.CRITERION(output, target).item()\n",
    "        val_loss /= len(self.valloader[0].dataset)\n",
    "        if self.early_stopper.best_loss is None or val_loss < self.early_stopper.best_loss:\n",
    "            print(\"Validation loss improved. Saving model...\")\n",
    "            self.save()\n",
    "        self.early_stopper(val_loss)\n",
    "    \n",
    "    def test(self):\n",
    "        self.server_model.eval()\n",
    "        \n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batches in enumerate(zip(*self.testloader)):\n",
    "                # batches is tuple of batch from each loader\n",
    "                data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "                target = batches[0][1].to(self.device).long()\n",
    "                client_activations = []\n",
    "                for data, client_base_model in zip(data_slices, self.client_base_models):\n",
    "                    #Client FeedForward\n",
    "                    client_base_model.eval()\n",
    "                    activation = client_base_model(data)\n",
    "                    client_activations.append(activation)\n",
    "                concat_activations = torch.cat(client_activations, dim=1)\n",
    "                #Server FeedForward\n",
    "                self.server_model.eval()\n",
    "                output = self.server_model(concat_activations)\n",
    "                test_loss +=  self.CRITERION(output, target).item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(self.testloader[0].dataset)\n",
    "        accuracy = 100. * correct / len(self.testloader[0].dataset)\n",
    "        if self.log: \n",
    "            self.test_losses.append(test_loss)\n",
    "            self.accuracies.append(accuracy)\n",
    "        print(f'\\nTest set: Average loss per Sample: {test_loss:.4f}, Accuracy: {correct}/{len(self.testloader[0].dataset)} '\n",
    "            f'({accuracy:.0f}%)\\n')\n",
    "            \n",
    "    def run_training(self, trainset, testset):\n",
    "        self.early_stopper = EarlyStopper()\n",
    "        self._to_loader(trainset, testset, \n",
    "            self.model_config.BATCH_SIZE_TRAIN,\n",
    "            self.model_config.BATCH_SIZE_VAL, \n",
    "            self.model_config.BATCH_SIZE_TEST, \n",
    "            self.model_config.TRAIN_SHUFFLE,\n",
    "            self.model_config.VAL_SHUFFLE, \n",
    "            self.model_config.TEST_SHUFFLE,\n",
    "            self.model_config.TRAIN_RATIO)\n",
    "        self.test()\n",
    "        for epoch in range(1, self.model_config.N_EPOCH + 1):\n",
    "            self.train(epoch)\n",
    "            self.test()\n",
    "            #if self.early_stopper.early_stop:\n",
    "            #    self.early_stop_epoch = epoch\n",
    "            #    print(\"early_stop_triggered\")\n",
    "            #   break\n",
    "        self.run_head_training()\n",
    "            \n",
    "    def pred(self, testset,  pred=True):\n",
    "        predictions = []\n",
    "        outputs = []\n",
    "        loader = self._pred_loader(testset, self.model_config.BATCH_SIZE_TEST, self.model_config.TEST_SHUFFLE)\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batches in enumerate(zip(*loader)):\n",
    "                # batches is tuple of batch from each loader\n",
    "                data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "                target = batches[0][1].to(self.device).long()\n",
    "                client_activations = []\n",
    "                for data, client_base_model in zip(data_slices, self.client_base_models):\n",
    "                    #Client FeedForward\n",
    "                    client_base_model.eval()\n",
    "                    activation = client_base_model(data)\n",
    "                    client_activations.append(activation)\n",
    "                concat_activations = torch.cat(client_activations, dim=1)\n",
    "                #Server FeedForward\n",
    "                self.server_model.eval()\n",
    "                output = self.server_model(concat_activations)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                predictions = predictions + pred.squeeze().tolist()\n",
    "        return predictions\n",
    "\n",
    "    def save(self):\n",
    "        result_path = f\"./results/split/{self.data_config.DATASET_NAME}/{self.seed}\"\n",
    "        os.makedirs(result_path, exist_ok=True)\n",
    "        model_path = os.path.join(result_path, f'model_server_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        optimizer_path = os.path.join(result_path, f'optimizer_server_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        torch.save(self.server_model.state_dict(), model_path)\n",
    "        torch.save(self.SERVER_OPTIMIZER.state_dict(), optimizer_path)\n",
    "\n",
    "        client_result_path =os.path.join(result_path, \"clients\")\n",
    "        os.makedirs(client_result_path, exist_ok=True)\n",
    "        for i, client_base_model in enumerate(self.client_base_models): \n",
    "            model_path = os.path.join(client_result_path, f'model_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            optimizer_path = os.path.join(client_result_path, f'optimizer_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            torch.save(client_base_model.state_dict(), model_path)\n",
    "            torch.save(self.CLIENT_BASE_OPTIMIZERS[i].state_dict(), optimizer_path)\n",
    "                    \n",
    "                   \n",
    "    def load(self):\n",
    "        result_path = f\"./results/split/{self.data_config.DATASET_NAME}/{self.seed}\"\n",
    "        model_path = os.path.join(result_path, f'model_server_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        optimizer_path = os.path.join(result_path, f'optimizer_server_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "        network_state_dict = torch.load(model_path)\n",
    "        self.server_model.load_state_dict(network_state_dict)\n",
    "        optimizer_state_dict = torch.load(optimizer_path)\n",
    "        self.SERVER_OPTIMIZER.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "        client_result_path =os.path.join(result_path, \"clients\")\n",
    "        for i, client_base_model in enumerate(self.client_base_models): \n",
    "            model_path = os.path.join(client_result_path, f'model_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            optimizer_path = os.path.join(client_result_path, f'optimizer_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "            network_state_dict = torch.load(model_path)\n",
    "            torch.save(clien_base_model.state_dict(), model_path)\n",
    "            torch.save(self.CLIENT_BASE_OPTIMIZERS[i].state_dict(), optimizer_path)\n",
    "                            \n",
    "    def classifier_test(self):\n",
    "        \n",
    "        test_loss_values = [0 for c in self.client_base_models]\n",
    "        correct_values = [0 for c in self.client_base_models]\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batches in enumerate(zip(*self.testloader)):\n",
    "                data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "                target = batches[0][1].to(self.device).long()\n",
    "                for client_idx, client in enumerate(zip(data_slices, self.client_base_models, self.client_classifier_models)):\n",
    "                    data, client_base_model, classifier_model = client \n",
    "                    client_base_model.train()\n",
    "                    activation = client_base_model(data)\n",
    "                    classifier_output = classifier_model(activation)\n",
    "                    test_loss_values[client_idx] +=  self.LOCAL_CLASSIFIER_CRITERION(classifier_output, target).item()\n",
    "                    pred = classifier_output.argmax(dim=1, keepdim=True)\n",
    "                    correct_values[client_idx]+= pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss_values = [t/ len(self.testloader[0].dataset) for t in test_loss_values]\n",
    "        accuracy_values = [100. * c / len(self.testloader[0].dataset) for c in correct_values]\n",
    "\n",
    "        if self.log: \n",
    "            self.test_losses.append(test_loss_values)\n",
    "            self.accuracies.append(accuracy_values)\n",
    "        print(f'\\nTest set: Average loss per Sample: {test_loss_values}, Accuracy: {correct_values}/{len(self.testloader[0].dataset)}'\n",
    "            f'({accuracy_values}%)\\n')\n",
    "        \n",
    "    def classifier_train(self, epoch):\n",
    "        for batch_idx, batches in enumerate(zip(*self.trainloader)):\n",
    "            # batches is tuple of batch from each loader\n",
    "            data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "            target = batches[0][1].to(self.device).long()\n",
    "            client_activations = []\n",
    "            for client_idx, client in enumerate(zip(data_slices, self.client_base_models, self.client_classifier_models, self.client_ig_models, self.CLIENT_CLASSIFIER_OPTIMIZERS, self.CLIENT_IG_OPTIMIZERS)):\n",
    "                data, client_base_model, classifier_model, client_ig_model, classifier_optimizer, ig_optimizer = client\n",
    "                #Client FeedForward\n",
    "                client_base_model.train()\n",
    "                activation = client_base_model(data)\n",
    "                activation.requires_grad_()\n",
    "                client_activations.append(activation)\n",
    "                #Classifier\n",
    "                classifier_optimizer.zero_grad()\n",
    "                classifier_output = classifier_model(activation)\n",
    "                loss = self.LOCAL_CLASSIFIER_CRITERION(classifier_output, target)\n",
    "                grads = torch.autograd.grad(loss, [activation] + list(classifier_model.parameters()))\n",
    "                concat_activation_grad = grads[0]\n",
    "                model_grads = grads[1:]\n",
    "                # Apply gradients manually to model parameters\n",
    "                for param, grad in zip(classifier_model.parameters(), model_grads):\n",
    "                    param.grad = grad  # Set .grad for optimizer\n",
    "                classifier_optimizer.step()\n",
    "                if self.log and batch_idx % self.log_interval == 0:\n",
    "                    print(f'Train Epoch: {epoch} Client {client_idx} [{batch_idx * len(data)}/{len(self.trainloader[0].dataset)} '\n",
    "                        f'({100. * batch_idx / len(self.trainloader[0]):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "            concat_activations = torch.cat(client_activations, dim=1)\n",
    "            \n",
    "    def gate_train(self, epoch):  \n",
    "        for batch_idx, batches in enumerate(zip(*self.trainloader)):\n",
    "            data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "            target = batches[0][1].to(self.device).long()\n",
    "            client_info = []\n",
    "            for client_idx, client in enumerate(zip(data_slices, self.client_base_models, self.client_ig_models, self.CLIENT_IG_OPTIMIZERS)):\n",
    "                data, client_base_model, classifier_model, client_ig_model, ig_optimizer = client\n",
    "                #Client FeedForward\n",
    "                client_base_model.train()\n",
    "                activation = client_base_model(data)\n",
    "                activation.requires_grad_()\n",
    "                classifier_output = classifier_model(activation)\n",
    "                classifier_pred = classifier_output.argmax(dim=1)\n",
    "                # Save everything for later use\n",
    "                client_info.append({\n",
    "                    'activation': activation,\n",
    "                    'classifier_output': classifier_output,\n",
    "                    'classifier_pred': classifier_pred,\n",
    "                    'ig_model': ig_model,\n",
    "                    'ig_optimizer': ig_optimizer\n",
    "                })\n",
    "                \n",
    "            concat_activations = torch.cat(client_activations, dim=1)\n",
    "            #Server FeedForward\n",
    "            self.server_model.train()\n",
    "            self.SERVER_OPTIMIZER.zero_grad()\n",
    "            server_output = self.server_model(concat_activations)\n",
    "            server_pred = server_output.argmax(dim=1)\n",
    "            \n",
    "            for idx, info in enumerate(client_info):\n",
    "                activation = info['activation']\n",
    "                classifier_pred = info['classifier_pred']\n",
    "                ig_model = info['ig_model']\n",
    "                ig_optimizer = info['ig_optimizer']\n",
    "                ig_optimizer.train()\n",
    "                ig_optimizer.zero_grad()\n",
    "    \n",
    "                client_wrong = (classifier_pred != target)\n",
    "                server_right = (server_pred == target)\n",
    "                ig_target = (client_wrong & server_right).float().unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "    \n",
    "                ig_output = ig_model(activation) \n",
    "    \n",
    "                ig_loss = self.LOCAL_IG_CRITERION(ig_output, ig_target)\n",
    "                grads = torch.autograd.grad(loss, [activation] + list(ig_model.parameters()))\n",
    "                concat_activation_grad = grads[0]\n",
    "                model_grads = grads[1:]\n",
    "                for param, grad in zip(classifier_model.parameters(), model_grads):\n",
    "                    param.grad = grad  # Set .grad for optimizer\n",
    "                ig_optimizer.step()\n",
    "\n",
    "    def gate_pred(self): \n",
    "        for batch_idx, batches in enumerate(zip(*self.testloader)):\n",
    "            data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "            target = batches[0][1].to(self.device).long()\n",
    "            ig_outputs = []\n",
    "            for client_idx, client in enumerate(zip(data_slices, self.client_base_models, self.client_ig_models)):\n",
    "                data, client_base_model, classifier_model, client_ig_model = client\n",
    "                #Client FeedForward\n",
    "                client_base_model.eval()\n",
    "                activation = client_base_model(data)\n",
    "                ig_output = ig_model(activation) \n",
    "                ig_outputs.append(ig_output)\n",
    "            return ig_outputs, target\n",
    "                \n",
    "                 \n",
    "    def run_head_training(self):\n",
    "        self.classifier_test()\n",
    "        for epoch in range(1, self.model_config.N_EPOCH + 1):\n",
    "            self.classifier_train(epoch)\n",
    "            self.classifier_test()\n",
    "\n",
    "    def run_gate_training(self):\n",
    "        for epoch in range(1, self.model_config.N_EPOCH + 1):\n",
    "            self.gate_train(epoch)\n",
    "\n",
    "            \n",
    "\n",
    "from federated_inference.common.environment import  DataMode, DataSetEnum, TransformType\n",
    "from federated_inference.simulations.simulation import Simulation\n",
    "import os\n",
    "import pandas as pd\n",
    "from federated_inference.simulations.simulation import Simulation\n",
    "from federated_inference.simulations.utils import *\n",
    "class IGSimulation(Simulation): \n",
    "    def __init__(self, seed, data_config, transform_config, server_model, client_base_model, client_classifier_model, client_ig_model, transform_type: TransformType = TransformType.FULL_STRIDE_PARTITION, exist=False):\n",
    "        self.seed = seed\n",
    "        self.data_config = data_config\n",
    "        self.transform_config = transform_config\n",
    "        self.server_model_config = ModelConfiguration\n",
    "        self.data_mode = DataMode.VERTICAL\n",
    "        self.transform_type = transform_type\n",
    "        self.dataset =  self.load_data(data_config)\n",
    "        self.client_datasets, self.transformation = self.transform_data(self.dataset, data_mode = self.data_mode, transform_config = transform_config, transform_type = self.transform_type)\n",
    "        self.clients = [IGV1Client(idx, data_config, dataset, data_config.LABELS) for idx, dataset in enumerate(self.client_datasets)]\n",
    "        self.server = IGV1Server(0, seed, ModelConfiguration(server_model, client_base_model, client_classifier_model, client_ig_model), self.data_config)\n",
    "        \n",
    "        self.cost_summary = {\n",
    "            'overall_cost' : 0, \n",
    "            'reasons': []\n",
    "        }\n",
    "\n",
    "    def train(self): \n",
    "        datasets = [client.send_all() for client in self.clients]\n",
    "        testsets = [client.request_pred(pred_all = True, keep_label = True) for client in self.clients]\n",
    "        self.server.run_training(datasets, testsets)\n",
    "\n",
    "    def test_inference(self):\n",
    "        testsets = [client.request_pred(pred_all = True, keep_label = True) for client in self.clients]\n",
    "        predictions = self.server.pred(testsets)\n",
    "        self.clients[0].check(predictions)\n",
    "        self.collect_results(self.seed, save = True)\n",
    "\n",
    "    def collect_results(self, name: str, save: bool = True, figures: bool = False):\n",
    "        from IPython.display import display\n",
    "        import json\n",
    "        import os\n",
    "\n",
    "        self.results = {\n",
    "            'seed': name,\n",
    "            'client': [],\n",
    "            'server': {}\n",
    "        }\n",
    "\n",
    "        if figures:\n",
    "            fig = create_simulation_image_subplots(simulation)\n",
    "            display(fig)\n",
    "\n",
    "        # Collect server results\n",
    "        self.results['server'] = self._gather_server_results(self.server)\n",
    "\n",
    "        # Collect results for the first (and only) client\n",
    "        client = self.clients[0]\n",
    "        client_result = self._gather_client_result(client, figures)\n",
    "        self.results['client'].append(client_result)\n",
    "\n",
    "        # Save results\n",
    "        if save:\n",
    "            self._save_results(str(name), base_dir=\"naive\")\n",
    "        return self.results\n",
    "\n",
    "    def _gather_server_results(self, server):\n",
    "        return {\n",
    "            'training_losses': server.train_losses,\n",
    "            'test_losses': server.test_losses\n",
    "        }\n",
    "\n",
    "    def _gather_client_result(self, client, figures):\n",
    "        from IPython.display import display\n",
    "\n",
    "        result = {\n",
    "            'idx': client.idx,\n",
    "            'cm': client.cm.to_json(orient='split')\n",
    "        }\n",
    "\n",
    "        analysis, df_cm_per = cm_analysis(client)\n",
    "        result['cm_analysis'] = analysis\n",
    "\n",
    "        # Extract relevant class indices\n",
    "        indices = [\n",
    "            analysis['correct']['most_correct_class'],\n",
    "            analysis['wrong']['most_misclassified_class']\n",
    "        ]\n",
    "        indices += [i for i in [analysis['wrong']['wrong_from'], analysis['wrong']['wrong_to']] if i not in indices]\n",
    "\n",
    "        # Add performance metrics\n",
    "        result.update({\n",
    "            'accuracy': analysis[\"performance\"][\"accuracy\"],\n",
    "            'precision': analysis[\"performance\"][\"precision\"],\n",
    "            'recall': analysis[\"performance\"][\"recall\"]\n",
    "        })\n",
    "\n",
    "        # Generate figures if needed\n",
    "        if figures:\n",
    "            display(plot_test_loss(client.test_losses, 1, client.idx, \"Test\"))\n",
    "            fig, subplot_indices = create_client_image_subplots(self, [client.idx], 8, keys=indices)\n",
    "            display(fig)\n",
    "            result['client_image_subplots_ids'] = subplot_indices\n",
    "            fig = print_cm_heat(df_cm_per, client.idx)\n",
    "            display(fig)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _save_results(self, name, base_dir=\"ig\"):\n",
    "        import os\n",
    "        import json\n",
    "\n",
    "        result_path = os.path.join(\"./results\", base_dir , self.data_config.DATASET_NAME, name)\n",
    "        os.makedirs(result_path, exist_ok=True)\n",
    "        file_path = os.path.join(result_path, \"simulation.json\")\n",
    "\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(self.results, f, indent=4)\n",
    "        print(\"Results saved to JSON.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9d8f9-a405-43f4-aeb9-6940a0a46b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_inference.simulations.naive.configs.data_config import DataConfiguration\n",
    "from federated_inference.simulations.naive.configs.transform_config import DataTransformConfiguration\n",
    "seed = 1\n",
    "set_seed(seed)\n",
    "data_config = DataConfiguration()\n",
    "transform_config = DataTransformConfiguration()\n",
    "simulation = IGSimulation(seed, data_config, transform_config, SplitServerCNN, IGV1Base, IGV1ClassifierHead, InformationGateV1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087601f0-7346-4ddb-986b-8352645390a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simulation.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95057f8f-39ad-412c-ba39-5e4b3b702c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gate_train(self, epoch):  \n",
    "    for batch_idx, batches in enumerate(zip(*self.trainloader)):\n",
    "        data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "        target = batches[0][1].to(self.device).long()\n",
    "        client_info = []\n",
    "        client_activations = []\n",
    "        for client_idx, client in enumerate(zip(data_slices, self.client_base_models, self.client_classifier_models, self.client_ig_models, self.CLIENT_IG_OPTIMIZERS)):\n",
    "            data, client_base_model, classifier_model, ig_model, ig_optimizer = client\n",
    "            #Client FeedForward\n",
    "            client_base_model.train()\n",
    "            activation = client_base_model(data)\n",
    "            activation.requires_grad_()\n",
    "            classifier_output = classifier_model(activation)\n",
    "            classifier_pred = classifier_output.argmax(dim=1)\n",
    "            client_activations.append(activation)\n",
    "            client_info.append({\n",
    "                'activation': activation,\n",
    "                'classifier_output': classifier_output,\n",
    "                'classifier_pred': classifier_pred,\n",
    "                'ig_model': ig_model,\n",
    "                'ig_optimizer': ig_optimizer\n",
    "            })\n",
    "            \n",
    "        concat_activations = torch.cat(client_activations, dim=1)\n",
    "        #Server FeedForward\n",
    "        self.server_model.train()\n",
    "        self.SERVER_OPTIMIZER.zero_grad()\n",
    "        server_output = self.server_model(concat_activations)\n",
    "        server_pred = server_output.argmax(dim=1)\n",
    "        \n",
    "        for idx, info in enumerate(client_info):\n",
    "            activation = info['activation']\n",
    "            classifier_pred = info['classifier_pred']\n",
    "            ig_model = info['ig_model']\n",
    "            ig_optimizer = info['ig_optimizer']\n",
    "            ig_model.train()\n",
    "            ig_optimizer.zero_grad()\n",
    "\n",
    "            \n",
    "            client_wrong = (classifier_pred != target)\n",
    "            server_right = (server_pred == target)\n",
    "            ig_target = (client_wrong & server_right).float().unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "\n",
    "            ig_output = ig_model(activation) \n",
    "\n",
    "            ig_loss = self.LOCAL_IG_CRITERION(ig_output, ig_target)\n",
    "            grads = torch.autograd.grad(ig_loss, [activation] + list(ig_model.parameters()))\n",
    "            concat_activation_grad = grads[0]\n",
    "            model_grads = grads[1:]\n",
    "            for param, grad in zip(ig_model.parameters(), model_grads):\n",
    "                param.grad = grad\n",
    "            ig_optimizer.step()\n",
    "for epoch in range(1, 30):\n",
    "    gate_train(simulation.server, epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c6f58-ae8e-48bf-94ed-bc30ff56b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gate_train(self, epoch):  \n",
    "    for batch_idx, batches in enumerate(zip(*self.trainloader)):\n",
    "        data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "        target = batches[0][1].to(self.device).long()\n",
    "\n",
    "        client_info = []\n",
    "        client_activations = []\n",
    "\n",
    "        for data, base_model, classifier_model, ig_model, ig_optimizer in zip(\n",
    "            data_slices, self.client_base_models, self.client_classifier_models,\n",
    "            self.client_ig_models, self.CLIENT_IG_OPTIMIZERS\n",
    "        ):\n",
    "            base_model.eval()\n",
    "            classifier_model.eval()\n",
    "            ig_model.train()\n",
    "\n",
    "            # Client base model forward\n",
    "            activation = base_model(data)\n",
    "            activation.requires_grad_()\n",
    "            classifier_output = classifier_model(activation)\n",
    "            classifier_loss = self.LOCAL_CLASSIFIER_CRITERION(classifier_output, target)\n",
    "\n",
    "            # Save for server input\n",
    "            client_info.append({\n",
    "                'activation': activation,\n",
    "                'ig_model': ig_model,\n",
    "                'ig_optimizer': ig_optimizer,\n",
    "                'classifier_loss': classifier_loss\n",
    "            })\n",
    "            client_activations.append(activation)\n",
    "\n",
    "        # Server model forward\n",
    "        concat_activations = torch.cat(client_activations, dim=1)\n",
    "        self.server_model.train()\n",
    "        server_output = self.server_model(concat_activations)\n",
    "        server_loss = self.CRITERION(server_output, target)\n",
    "\n",
    "        for info in client_info:\n",
    "            activation = info['activation']\n",
    "            ig_model = info['ig_model']\n",
    "            ig_optimizer = info['ig_optimizer']\n",
    "            classifier_loss = info['classifier_loss']\n",
    "            ig_optimizer.zero_grad()\n",
    "            # Forward through IG\n",
    "            ig_output = ig_model(activation).squeeze(1)  # shape: [batch_size, 1] with sigmoid output\n",
    "\n",
    "            # Soft-gating loss: IG(x) * local_loss + (1 - IG(x)) * server_loss\n",
    "            loss = (1-ig_output) * 0.002 * classifier_loss + (ig_output) * server_loss\n",
    "            loss = loss.mean()\n",
    "\n",
    "            # Backprop\n",
    "            grads = torch.autograd.grad(loss, [activation] + list(ig_model.parameters()), retain_graph=True)\n",
    "            concat_activation_grad = grads[0]\n",
    "            model_grads = grads[1:]\n",
    "            for param, grad in zip(ig_model.parameters(), model_grads):\n",
    "                param.grad = grad\n",
    "            ig_optimizer.step()\n",
    "            \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Batch {batch_idx}, IG output mean: {ig_output.mean().item():.4f}\")\n",
    "\n",
    "for epoch in range(1, 30):\n",
    "    gate_train(simulation.server, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb186f7-b010-4411-9970-36e02e25464b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gate_pred(self): \n",
    "    ig_outputs = [ [] for i in range(self.number_of_clients)]\n",
    "    targets = []\n",
    "    for batch_idx, batches in enumerate(zip(*self.testloader)):\n",
    "        data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "        target = batches[0][1].to(self.device).long()\n",
    "        targets = targets + target.squeeze().tolist()\n",
    "        for client_idx, client in enumerate(zip(data_slices, self.client_base_models, self.client_ig_models)):\n",
    "            data, client_base_model, ig_model = client\n",
    "            #Client FeedForward\n",
    "            client_base_model.eval()\n",
    "            ig_model.eval()\n",
    "            activation = client_base_model(data)\n",
    "            ig_output = ig_model(activation) \n",
    "            ig_outputs[client_idx] = ig_outputs[client_idx] + ig_output.squeeze().tolist()\n",
    "    return ig_outputs, targets\n",
    "ig_outputs, targets = gate_pred(simulation.server)\n",
    "import numpy as np\n",
    "for i in range(4):\n",
    "    from collections import Counter\n",
    "    filtered_targets = np.array(targets)[np.array(ig_outputs[i]) > 0.25]\n",
    "    counts = Counter(filtered_targets)\n",
    "    #print(ig_outputs)\n",
    "    print(counts, len(filtered_targets)/len(ig_outputs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92a92c5-55ae-4d01-8e74-d8c86624e218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_inference(self):\n",
    "    for i in range(self.number_of_clients):\n",
    "        correct = 0\n",
    "        client_correct = 0\n",
    "        server_correct = 0\n",
    "        client_instance = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batches in enumerate(zip(*self.testloader)):\n",
    "                    # Step 1: Get data and target\n",
    "                    data_slices = [batch[0].to(self.device).float() for batch in batches]\n",
    "                    target = batches[0][1].to(self.device).long()\n",
    "                    # Step 2: Run base model and IG for active client (client 0)\n",
    "                    active_client = list(zip(data_slices, self.client_base_models, self.client_classifier_models, self.client_ig_models))[i]\n",
    "                    active_data, base_model, classifier_model, ig_model = active_client\n",
    "                    \n",
    "                    base_model.eval()\n",
    "                    activation = base_model(active_data)\n",
    "                    \n",
    "                    ig_model.eval()\n",
    "                    ig_output = ig_model(activation).squeeze()  # Make sure it's shape [batch_size]\n",
    "        \n",
    "                    # Step 3: Split by IG threshold\n",
    "                    low_mask = (ig_output < 0.25).to(self.device)\n",
    "                    high_mask = (ig_output >= 0.25).to(self.device)\n",
    "        \n",
    "                    # Step 4: Local classifier inference for low IG samples\n",
    "                    low_target = target[low_mask]\n",
    "                    client_instance += len(low_target)\n",
    "                    activation_low = activation[low_mask]\n",
    "                    if len(low_target) > 0:\n",
    "                        classifier_model.eval()\n",
    "                        local_output = classifier_model(activation_low)\n",
    "                        classifier_pred = local_output.argmax(dim=1)\n",
    "                        correct += classifier_pred.eq(low_target).sum().item()\n",
    "                        client_correct += classifier_pred.eq(low_target).sum().item()\n",
    "            \n",
    "                    # Step 5: Prepare activations from all clients for high IG samples\n",
    "                    high_data_slices = [batch[0].to(self.device)[high_mask].to(self.device).float() for batch in batches]\n",
    "                    high_target = target[high_mask]\n",
    "        \n",
    "                    if len(high_target) > 0:\n",
    "                        client_activations = []\n",
    "                        for data, base_model, classifier_model, ig_model in zip(high_data_slices, self.client_base_models, self.client_classifier_models, self.client_ig_models):\n",
    "                            if len(data) > 0:\n",
    "                                base_model.eval()\n",
    "                                activation = base_model(data)\n",
    "                                client_activations.append(activation)\n",
    "                \n",
    "                        if client_activations:  # Avoid torch.cat error on empty list\n",
    "                            concat_activations = torch.cat(client_activations, dim=1)\n",
    "            \n",
    "                            # Step 6: Server-side inference\n",
    "                            self.server_model.eval()\n",
    "                            output = self.server_model(concat_activations)\n",
    "                            pred = output.argmax(dim=1)\n",
    "                            correct += pred.eq(high_target).sum().item()\n",
    "                            server_correct += pred.eq(high_target).sum().item()\n",
    "        \n",
    "            print(correct / len(self.testloader[0].dataset))\n",
    "            print(client_correct/client_instance, client_instance)\n",
    "            print(server_correct/(len(self.testloader[0].dataset) - client_instance), (len(self.testloader[0].dataset) - client_instance))\n",
    "test_inference(simulation.server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84f80ed-1ee7-4f31-bd37-d9e8cb6f082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_inference.simulations.utils import *\n",
    "simulation.test_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5903f9e2-24b9-4f89-9874-2d9a69b1e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(self):\n",
    "    result_path = f\"./results/split/{self.data_config.DATASET_NAME}/{self.seed}\"\n",
    "    os.makedirs(result_path, exist_ok=True)\n",
    "    model_path = os.path.join(result_path, f'model_server_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "    optimizer_path = os.path.join(result_path, f'optimizer_server_{self.idx}.pth').replace(\"\\\\\", \"/\")\n",
    "    torch.save(self.server_model.state_dict(), model_path)\n",
    "    torch.save(self.SERVER_OPTIMIZER.state_dict(), optimizer_path)\n",
    "\n",
    "    client_base_result_path =os.path.join(result_path, \"clients\", \"base\")\n",
    "    os.makedirs(client_base_result_path, exist_ok=True)\n",
    "    for i, client_base_model in enumerate(self.client_base_models): \n",
    "        model_path = os.path.join(client_base_result_path, f'model_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "        optimizer_path = os.path.join(client_base_result_path, f'optimizer_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "        torch.save(client_base_model.state_dict(), model_path)\n",
    "        torch.save(self.CLIENT_BASE_OPTIMIZERS[i].state_dict(), optimizer_path)\n",
    "\n",
    "    clients_result_path =os.path.join(result_path, \"clients\", \"ig\")\n",
    "    os.makedirs(clients_result_path, exist_ok=True)\n",
    "    for i, client_base_model in enumerate(self.client_ig_models): \n",
    "        model_path = os.path.join(clients_result_path, f'model_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "        optimizer_path = os.path.join(clients_result_path, f'optimizer_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "        torch.save(client_base_model.state_dict(), model_path)\n",
    "        torch.save(self.CLIENT_IG_OPTIMIZERS[i].state_dict(), optimizer_path)\n",
    "        \n",
    "    clients_result_path = os.path.join(result_path, \"clients\", \"classifier\")\n",
    "    os.makedirs(clients_result_path, exist_ok=True)\n",
    "    for i, client_base_model in enumerate(self.client_ig_models): \n",
    "        model_path = os.path.join(clients_result_path, f'model_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "        optimizer_path = os.path.join(clients_result_path, f'optimizer_client_{i}.pth').replace(\"\\\\\", \"/\")\n",
    "        torch.save(client_base_model.state_dict(), model_path)\n",
    "        torch.save(self.CLIENT_CLASSIFIER_OPTIMIZERS[i].state_dict(), optimizer_path)\n",
    "                \n",
    "\n",
    "                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
