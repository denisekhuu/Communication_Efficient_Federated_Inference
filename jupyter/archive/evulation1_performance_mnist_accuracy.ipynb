{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40fcad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead72df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4974135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_inference.common.utils import set_seed\n",
    "from federated_inference.configs.data_config import DataConfiguration\n",
    "from federated_inference.configs.transform_config import DataTransformConfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6f8dad",
   "metadata": {},
   "source": [
    "# Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9dbee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from federated_inference.simulations.hybrid.simulation import HybridSplitSimulation\n",
    "DATASET = 'MNIST'\n",
    "SEEDS = [4,13,27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_inference.simulations.hybrid.v6.models import GlobalHybridSplitClassifierHead, HybridSplitBase, LocalHybridSplitClassifierHead, RouterHead\n",
    "VERSION = \"v61\"\n",
    "h1_clients_preds = {}\n",
    "h1_clients_routers = {}\n",
    "h1_server_preds = {}\n",
    "h1_targets = {}\n",
    "\n",
    "for seed in SEEDS:\n",
    "    set_seed(seed)\n",
    "    data_config = DataConfiguration(DATASET)\n",
    "    transform_config = DataTransformConfiguration()\n",
    "    simulation_hybrid_1 = HybridSplitSimulation(seed, VERSION,  data_config, transform_config, GlobalHybridSplitClassifierHead, HybridSplitBase, LocalHybridSplitClassifierHead, RouterHead)\n",
    "    simulation_hybrid_1.server.load()\n",
    "    _testsets = [client.request_pred(pred_all = True, keep_label = True) for client in simulation_hybrid_1.clients]\n",
    "    h1_clients_pred, h1_clients_router, h1_server_pred = simulation_hybrid_1.server.run_infernces(_testsets)\n",
    "    h1_clients_targets =  simulation_hybrid_1.server.testloaders[0].dataset.targets \n",
    "    h1_clients_preds[seed] = h1_clients_pred\n",
    "    h1_clients_routers[seed] = h1_clients_router\n",
    "    h1_server_preds[seed] =  h1_server_pred \n",
    "    h1_targets[seed] = simulation_hybrid_1.server.testloaders[0].dataset.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7643a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(h1_clients_preds[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad657a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(h1_server_preds[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93442b61",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2afd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from federated_inference.simulations.hybrid.v7.models import GlobalHybridSplitClassifierHead, HybridSplitBase, LocalHybridSplitClassifierHead, RouterHead\n",
    "VERSION = \"v71\"\n",
    "h2_clients_preds = {}\n",
    "h2_clients_routers = {}\n",
    "h2_server_preds = {}\n",
    "h2_targets = {}\n",
    "\n",
    "for seed in SEEDS:\n",
    "    set_seed(seed)\n",
    "    data_config = DataConfiguration(DATASET)\n",
    "    transform_config = DataTransformConfiguration()\n",
    "    simulation_hybrid_2 = HybridSplitSimulation(seed, VERSION,  data_config, transform_config, GlobalHybridSplitClassifierHead, HybridSplitBase, LocalHybridSplitClassifierHead, RouterHead)\n",
    "    simulation_hybrid_2.server.load()\n",
    "    _testsets = [client.request_pred(pred_all = True, keep_label = True) for client in simulation_hybrid_2.clients]\n",
    "    h2_clients_pred, h2_clients_router, h2_server_pred = simulation_hybrid_2.server.run_infernces(_testsets)\n",
    "    h2_clients_targets =  simulation_hybrid_2.server.testloaders[0].dataset.targets \n",
    "    h2_clients_preds[seed] = h2_clients_pred\n",
    "    h2_clients_routers[seed] = h2_clients_router\n",
    "    h2_server_preds[seed] =  h2_server_pred \n",
    "    h2_targets[seed] = simulation_hybrid_2.server.testloaders[0].dataset.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edefca5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef179f19",
   "metadata": {},
   "source": [
    "## On Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dcba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_inference.simulations.ondevice.simulation import OnDeviceVerticalSimulation\n",
    "from federated_inference.simulations.ondevice.models import OnDeviceMNISTModel\n",
    "VERSION = \"v1\"\n",
    "on_client_preds = {}\n",
    "for seed in SEEDS:\n",
    "    data_config = DataConfiguration(DATASET)\n",
    "    transform_config = DataTransformConfiguration()\n",
    "    simulation_on_client = OnDeviceVerticalSimulation(seed, VERSION, data_config, transform_config, OnDeviceMNISTModel, exist=False)\n",
    "    [client.load() for client in simulation_on_client.clients]\n",
    "    _testsets = [client.data.test_dataset for client in simulation_on_client.clients]\n",
    "    on_client_pred = simulation_on_client.run_inference(_testsets)\n",
    "    on_client_preds[seed] = on_client_pred\n",
    "    targets =  simulation_on_client.clients[0].data.test_dataset.dataset.targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d5cd63",
   "metadata": {},
   "source": [
    "## On Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e152c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from federated_inference.simulations.oncloud.simulation import OnCloudVerticalSimulation\n",
    "from federated_inference.simulations.oncloud.models.model import OnCloudMNISTModel\n",
    "VERSION = \"v1\"\n",
    "on_cloud_preds = {}\n",
    "for seed in SEEDS:\n",
    "    data_config = DataConfiguration(DATASET)\n",
    "    transform_config = DataTransformConfiguration()\n",
    "    simulation_on_cloud = OnCloudVerticalSimulation(seed, VERSION, data_config, transform_config, OnCloudMNISTModel, exist=False)\n",
    "    simulation_on_cloud.server.load()\n",
    "    _testsets = [client.data.test_dataset for client in simulation_on_cloud.clients]\n",
    "    on_cloud_pred = simulation_on_cloud.run_inference(_testsets)\n",
    "    on_cloud_preds[seed] = on_cloud_pred\n",
    "    targets =  simulation_on_cloud.clients[0].data.test_dataset.dataset.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74931ad9",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9751fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import accuracy_score\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "client_map = ['LT', 'RT', 'LB', \"RB\"]\n",
    "sub_labels = [\"V1\", \"V2\", \"Local-Only\"]\n",
    "server_labels = [\"Remote V1\", \" Remote V2\", \"Remote-Only\"]\n",
    "\n",
    "def compute_client_accs(client_preds_dict):\n",
    "    \"\"\"Returns mean and std accuracy for each client across seeds.\"\"\"\n",
    "    client_ids = range(4)\n",
    "\n",
    "    means = []\n",
    "    stds = []\n",
    "    for client in client_ids:\n",
    "        accs = []\n",
    "        for seed in client_preds_dict:\n",
    "            if client in client_preds_dict[seed]:\n",
    "                acc = accuracy_score(targets, client_preds_dict[seed][client])\n",
    "                accs.append(acc)\n",
    "        if accs:\n",
    "            means.append(np.mean(accs))\n",
    "            stds.append(np.std(accs))\n",
    "        else:\n",
    "            means.append(None)\n",
    "            stds.append(None)\n",
    "    return client_ids, means, stds\n",
    "\n",
    "\n",
    "def compute_server_accs(server_preds_dict):\n",
    "    \"\"\"Returns mean and std accuracy for a list of server predictions {seed: preds}\"\"\"\n",
    "    accs = [accuracy_score(targets, preds) for preds in server_preds_dict.values()]\n",
    "    return np.mean(accs), np.std(accs)\n",
    "\n",
    "\n",
    "all_client_ids = set()\n",
    "for preds_dict in [h1_clients_preds, h2_clients_preds, on_client_preds]:\n",
    "    for seed_preds in preds_dict.values():\n",
    "        all_client_ids.update(seed_preds.keys())\n",
    "all_client_ids = sorted(all_client_ids)\n",
    "n_clients = len(all_client_ids)\n",
    "\n",
    "\n",
    "_, h1_mean, h1_std = compute_client_accs(h1_clients_preds)\n",
    "_, h2_mean, h2_std = compute_client_accs(h2_clients_preds)\n",
    "_, local_mean, local_std = compute_client_accs(on_client_preds)\n",
    "\n",
    "h1_x, h2_x, local_x = [], [], []\n",
    "for i in range(n_clients):\n",
    "    base = i * 3\n",
    "    h1_x.append(base)\n",
    "    h2_x.append(base + 1)\n",
    "    local_x.append(base + 2)\n",
    "\n",
    "server_means = []\n",
    "server_stds = []\n",
    "for preds in [h1_server_preds, h2_server_preds, on_cloud_preds]:\n",
    "    mean, std = compute_server_accs(preds)\n",
    "    server_means.append(mean)\n",
    "    server_stds.append(std)\n",
    "server_x = [n_clients * 3 + i for i in range(3)]\n",
    "\n",
    "tickvals = [i * 3 + 1 for i in range(n_clients)] + server_x\n",
    "ticktext = client_map + server_labels\n",
    "\n",
    "annotations = []\n",
    "for i in range(n_clients):\n",
    "    for j, sublabel in enumerate(sub_labels):\n",
    "        annotations.append(dict(\n",
    "            x=i * 3 + j,\n",
    "            y=-0.1,\n",
    "            xref='x',\n",
    "            yref='paper',\n",
    "            text=sublabel,\n",
    "            showarrow=False,\n",
    "            font=dict(size=12),\n",
    "            yshift=-20,\n",
    "        ))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=h1_x,\n",
    "    y=h1_mean,\n",
    "    error_y=dict(type='data', array=h1_std, visible=True),\n",
    "    name=\"HF-NN V1\",\n",
    "    marker_color=\"blue\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=h2_x,\n",
    "    y=h2_mean,\n",
    "    error_y=dict(type='data', array=h2_std, visible=True),\n",
    "    name=\"HF-NN H2\",\n",
    "    marker_color=\"green\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=local_x,\n",
    "    y=local_mean,\n",
    "    error_y=dict(type='data', array=local_std, visible=True),\n",
    "    name=\"Local-Only\",\n",
    "    marker_color=\"orange\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=[server_x[0]],\n",
    "    y=[server_means[0]],\n",
    "    error_y=dict(type='data', array=server_stds, visible=True),\n",
    "    name=\"HF-NN V1\",\n",
    "    marker_color=\"blue\",\n",
    "    text=[f\"{server_means[0]:.2%}\"],\n",
    "    textposition=\"auto\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=[server_x[1]],\n",
    "    y=[server_means[1]],\n",
    "    error_y=dict(type='data', array=server_stds, visible=True),\n",
    "    name=\"H1 - Remote \",\n",
    "    marker_color=\"green\",\n",
    "    text=[f\"{server_means[1]:.2%}\"],\n",
    "    textposition=\"auto\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=[server_x[2]],\n",
    "    y=[server_means[2]],\n",
    "    error_y=dict(type='data', array=server_stds, visible=True),\n",
    "    name=\"Remote Only\",\n",
    "    marker_color=\"purple\",\n",
    "    text=[f\"{server_means[2]:.2%}\"],\n",
    "    textposition=\"auto\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    #title=\"Accuracy Comparison (Mean Â± Std over Seeds)\",\n",
    "    xaxis=dict(\n",
    "        title=\"Client ID / Server\",\n",
    "        tickmode='array',\n",
    "        tickvals=tickvals,\n",
    "        ticktext=ticktext,\n",
    "        tickangle=-80,\n",
    "    ),\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    yaxis_tickformat=\".0%\",\n",
    "    barmode=\"group\",\n",
    "    height=500,\n",
    "    margin=dict(l=40, r=40, t=60, b=140),\n",
    "    font=dict(size=14),\n",
    "    annotations=annotations,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9870546",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b838e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_mean, h1_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_mean, h2_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c58092",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_mean, local_std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8612cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_means, server_stds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34277f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(server_means)-min(server_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff05043",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(server_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb080eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(local_std), np.max(local_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a2bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "std_deviations_differences = []\n",
    "for i in range(10):\n",
    "    target_class = i  \n",
    "    client_map = ['LT', 'RT', 'LB', \"RB\"]\n",
    "    sub_labels = [\"V1\", \"V2\", \"Local-Only\"]\n",
    "    server_labels = [\"Remote V1\", \" Remote V2\", \"Remote-Only\"]\n",
    "\n",
    "    def compute_client_f1s(client_preds_dict, target_class):\n",
    "        \"\"\"Returns mean and std F1 score for each client across seeds for a specific class.\"\"\"\n",
    "        client_ids = range(4)\n",
    "\n",
    "        means = []\n",
    "        stds = []\n",
    "        for client in client_ids:\n",
    "            f1s = []\n",
    "            for seed in client_preds_dict:\n",
    "                if client in client_preds_dict[seed]:\n",
    "                    f1 = f1_score(targets, client_preds_dict[seed][client],\n",
    "                                labels=[target_class], average='macro', zero_division=0)\n",
    "                    f1s.append(f1)\n",
    "            if f1s:\n",
    "                means.append(np.mean(f1s))\n",
    "                stds.append(np.std(f1s))\n",
    "            else:\n",
    "                means.append(None)\n",
    "                stds.append(None)\n",
    "        return client_ids, means, stds\n",
    "\n",
    "    def compute_server_f1s(server_preds_dict, target_class):\n",
    "        f1s = [f1_score(targets, preds, labels=[target_class], average='macro', zero_division=0)\n",
    "            for preds in server_preds_dict.values()]\n",
    "        return np.mean(f1s), np.std(f1s)\n",
    "\n",
    "    all_client_ids = set()\n",
    "    for preds_dict in [h1_clients_preds, h2_clients_preds, on_client_preds]:\n",
    "        for seed_preds in preds_dict.values():\n",
    "            all_client_ids.update(seed_preds.keys())\n",
    "    all_client_ids = sorted(all_client_ids)\n",
    "    n_clients = len(all_client_ids)\n",
    "\n",
    "    _, f1_h1_mean, f1_h1_std = compute_client_f1s(h1_clients_preds, target_class)\n",
    "    _, f1_h2_mean, f1_h2_std = compute_client_f1s(h2_clients_preds, target_class)\n",
    "    _, f1_local_mean, f1_local_std = compute_client_f1s(on_client_preds, target_class)\n",
    "    std_deviations_differences.append(np.array(f1_h1_std)-np.array(f1_local_std))\n",
    "    std_deviations_differences.append(np.array(f1_h2_std)-np.array(f1_local_std))\n",
    "\n",
    "    h1_x, h2_x, local_x = [], [], []\n",
    "    for i in range(n_clients):\n",
    "        base = i * 3\n",
    "        h1_x.append(base)\n",
    "        h2_x.append(base + 1)\n",
    "        local_x.append(base + 2)\n",
    "\n",
    "    f1_server_means = []\n",
    "    f1_server_stds = []\n",
    "    for preds in [h1_server_preds, h2_server_preds, on_cloud_preds]:\n",
    "        mean, std = compute_server_f1s(preds, target_class)\n",
    "        f1_server_means.append(mean)\n",
    "        f1_server_stds.append(std)\n",
    "    server_x = [n_clients * 3 + i for i in range(3)]\n",
    "\n",
    "    tickvals = [i * 3 + 1 for i in range(n_clients)] + server_x\n",
    "    ticktext = client_map + server_labels\n",
    "\n",
    "    annotations = []\n",
    "    for i in range(n_clients):\n",
    "        for j, sublabel in enumerate(sub_labels):\n",
    "            annotations.append(dict(\n",
    "                x=i * 3 + j,\n",
    "                y=-0.1,\n",
    "                xref='x',\n",
    "                yref='paper',\n",
    "                text=sublabel,\n",
    "                showarrow=False,\n",
    "                font=dict(size=12),\n",
    "                yshift=-20,\n",
    "            ))\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=h1_x,\n",
    "        y=f1_h1_mean,\n",
    "        error_y=dict(type='data', array=f1_h1_std, visible=True),\n",
    "        name=\"H1\",\n",
    "        marker_color=\"blue\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=h2_x,\n",
    "        y=f1_h2_mean,\n",
    "        error_y=dict(type='data', array=f1_h2_std, visible=True),\n",
    "        name=\"H2\",\n",
    "        marker_color=\"green\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=local_x,\n",
    "        y=f1_local_mean,\n",
    "        error_y=dict(type='data', array=f1_local_std, visible=True),\n",
    "        name=\"Local-Only\",\n",
    "        marker_color=\"orange\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[server_x[0]],\n",
    "        y=[f1_server_means[0]],\n",
    "        error_y=dict(type='data', array=server_stds, visible=True),\n",
    "        name=\"HF-NN V1\",\n",
    "        marker_color=\"blue\",\n",
    "        text=[f\"{server_means[0]:.2%}\"],\n",
    "        textposition=\"auto\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[server_x[1]],\n",
    "        y=[f1_server_means[1]],\n",
    "        error_y=dict(type='data', array=server_stds, visible=True),\n",
    "        name=\"H1 - Remote \",\n",
    "        marker_color=\"green\",\n",
    "        text=[f\"{server_means[1]:.2%}\"],\n",
    "        textposition=\"auto\"\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[server_x[2]],\n",
    "        y=[f1_server_means[2]],\n",
    "        error_y=dict(type='data', array=server_stds, visible=True),\n",
    "        name=\"Remote Only\",\n",
    "        marker_color=\"purple\",\n",
    "        text=[f\"{server_means[2]:.2%}\"],\n",
    "        textposition=\"auto\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        #title=f\"F1-Score for Class {target_class} (Mean Â± Std over Seeds)\",\n",
    "        xaxis=dict(\n",
    "            title=\"Client ID / Server\",\n",
    "            tickmode='array',\n",
    "            tickvals=tickvals,\n",
    "            ticktext=ticktext,\n",
    "            tickangle=-80,\n",
    "        ),\n",
    "        yaxis_title=\"F1 Score\",\n",
    "        yaxis_tickformat=\".0%\",\n",
    "        barmode=\"group\",\n",
    "        height=500,\n",
    "        margin=dict(l=40, r=40, t=60, b=140),\n",
    "        annotations=annotations,\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(local_mean), np.mean(h1_mean), np.mean(h2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c56f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(local_std), np.mean(h1_std), np.mean(h2_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75197c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(std_deviations_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9376675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_coverage_and_accuracy_single_seed(seed_router_logits, seed_client_preds, targets):\n",
    "    \"\"\"\n",
    "    Compute coverage and hybrid accuracy for a single seed given router logits, client preds, and targets,\n",
    "    but only evaluate every 100th threshold for efficiency.\n",
    "\n",
    "    Args:\n",
    "        seed_router_logits: dict {client_id: np.array of router logits for each sample}\n",
    "        seed_client_preds: dict {client_id: np.array of predicted labels for each sample}\n",
    "        targets: np.array of true labels\n",
    "\n",
    "    Returns:\n",
    "        coverage: dict {threshold: {client_id: coverage_value}}\n",
    "        hybrid_accuracy: dict {client_id: {threshold: accuracy_value}}\n",
    "    \"\"\"\n",
    "\n",
    "    client_ids = sorted(seed_router_logits.keys())\n",
    "\n",
    "    # Gather all unique thresholds from all clients combined\n",
    "    all_logits = np.concatenate([seed_router_logits[cid] for cid in client_ids])\n",
    "    unique_thresholds = np.sort(np.unique(all_logits))[::-1]  # Descending thresholds\n",
    "\n",
    "    # Sample every 100th threshold\n",
    "    unique_thresholds = unique_thresholds[::100]\n",
    "\n",
    "    coverage = {}\n",
    "    hybrid_accuracy = {cid: {} for cid in client_ids}\n",
    "\n",
    "    for th in unique_thresholds:\n",
    "        coverage[th] = {}\n",
    "        for cid in client_ids:\n",
    "            logits = seed_router_logits[cid]\n",
    "            preds = seed_client_preds[cid]\n",
    "\n",
    "            # Ensure numpy arrays for indexing\n",
    "            logits = np.array(logits)\n",
    "            preds = np.array(preds)\n",
    "            targets_arr = np.array(targets[:len(preds)])  # Match size\n",
    "\n",
    "            selected = logits > th\n",
    "            cov_frac = 1.0 - np.mean(selected)\n",
    "            coverage[th][cid] = cov_frac\n",
    "\n",
    "            if np.any(selected):\n",
    "                acc = np.mean(preds[selected] == targets_arr[selected])\n",
    "            else:\n",
    "                acc = 0.0\n",
    "            hybrid_accuracy[cid][th] = acc\n",
    "\n",
    "    return coverage, hybrid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d4bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_coverage_and_accuracy_single_seed(seed_router_logits, seed_client_preds, targets):\n",
    "    \"\"\"\n",
    "    Compute coverage and hybrid accuracy for a single seed given router logits, client preds, and targets,\n",
    "    but only evaluate every 100th threshold for efficiency.\n",
    "\n",
    "    Args:\n",
    "        seed_router_logits: dict {client_id: np.array of router logits for each sample}\n",
    "        seed_client_preds: dict {client_id: np.array of predicted labels for each sample}\n",
    "        targets: np.array of true labels\n",
    "\n",
    "    Returns:\n",
    "        coverage: dict {threshold: {client_id: coverage_value}}\n",
    "        hybrid_accuracy: dict {client_id: {threshold: accuracy_value}}\n",
    "    \"\"\"\n",
    "\n",
    "    client_ids = sorted(seed_router_logits.keys())\n",
    "\n",
    "    # Gather all unique thresholds from all clients combined\n",
    "    all_logits = np.concatenate([seed_router_logits[cid] for cid in client_ids])\n",
    "    unique_thresholds = np.sort(np.unique(all_logits))[::-1]  # Descending thresholds\n",
    "\n",
    "    # Sample every 100th threshold\n",
    "    unique_thresholds = unique_thresholds[::100]\n",
    "\n",
    "    coverage = {}\n",
    "    hybrid_accuracy = {cid: {} for cid in client_ids}\n",
    "\n",
    "    for th in unique_thresholds:\n",
    "        coverage[th] = {}\n",
    "        for cid in client_ids:\n",
    "            logits = seed_router_logits[cid]\n",
    "            preds = seed_client_preds[cid]\n",
    "\n",
    "            # Ensure numpy arrays for indexing\n",
    "            logits = np.array(logits)\n",
    "            preds = np.array(preds)\n",
    "            targets_arr = np.array(targets[:len(preds)])  # Match size\n",
    "\n",
    "            selected = logits > th\n",
    "            cov_frac = 1.0 - np.mean(selected)\n",
    "            coverage[th][cid] = cov_frac\n",
    "\n",
    "            if np.any(selected):\n",
    "                acc = np.mean(preds[selected] == targets_arr[selected])\n",
    "            else:\n",
    "                acc = 0.0\n",
    "            hybrid_accuracy[cid][th] = acc\n",
    "\n",
    "    return coverage, hybrid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7e546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_h1_mean, f1_h1_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_h2_mean, f1_h2_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_local_mean, f1_local_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2ed4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_server_means, f1_server_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426dfcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in h1_server_preds.keys():\n",
    "    print(accuracy_score(h1_server_preds[s], h1_targets[s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in h2_server_preds.keys():\n",
    "    print(accuracy_score(h2_server_preds[s], h2_targets[s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7cb0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_clients_routers[4][0]\n",
    "h1_targets[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e1c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Data and settings\n",
    "bins = 30\n",
    "target_filter = list(range(10))  # ðŸ”§ Change to a single value (e.g., 0) or a list (e.g., [0, 2])\n",
    "classes = np.unique(h1_targets[13])\n",
    "logits = np.array(h1_clients_routers[13][3])\n",
    "targets = h1_targets[4]\n",
    "\n",
    "# Ensure target_filter is a list\n",
    "if not isinstance(target_filter, (list, np.ndarray)):\n",
    "    target_filter = [target_filter]\n",
    "\n",
    "# Compute histogram data for filtered classes\n",
    "hist_data = []\n",
    "bin_edges = None\n",
    "\n",
    "for cls in classes:\n",
    "    if cls not in target_filter:\n",
    "        continue\n",
    "\n",
    "    mask = targets == cls\n",
    "    class_logits = logits[mask]\n",
    "    counts, edges = np.histogram(class_logits, bins=bins)\n",
    "\n",
    "    if bin_edges is None:\n",
    "        bin_edges = edges\n",
    "\n",
    "    bin_centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "    hist_data.append((cls, bin_centers, counts))\n",
    "\n",
    "# Create Plotly figure\n",
    "fig = go.Figure()\n",
    "\n",
    "for cls, bin_centers, counts in hist_data:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=bin_centers,\n",
    "        y=counts,\n",
    "        name=f'Class {cls}',\n",
    "        opacity=0.6\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=f'Histogram of Router V1 Client LB by Class',\n",
    "    xaxis_title='Logit Value',\n",
    "    yaxis_title='Frequency',\n",
    "    barmode='overlay',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bc58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "bins = 30\n",
    "target_filter = list(range(10)) #  [1,3,5]\n",
    "classes = np.unique(h1_targets[27])\n",
    "logits = np.array(h1_clients_routers[27][1])\n",
    "targets = h1_targets[4]\n",
    "\n",
    "\n",
    "if not isinstance(target_filter, (list, np.ndarray)):\n",
    "    target_filter = [target_filter]\n",
    "\n",
    "hist_data = []\n",
    "bin_edges = None\n",
    "\n",
    "for cls in classes:\n",
    "    if cls not in target_filter:\n",
    "        continue\n",
    "\n",
    "    mask = targets == cls\n",
    "    class_logits = logits[mask]\n",
    "    counts, edges = np.histogram(class_logits, bins=bins)\n",
    "\n",
    "    if bin_edges is None:\n",
    "        bin_edges = edges\n",
    "\n",
    "    bin_centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "    hist_data.append((cls, bin_centers, counts))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for cls, bin_centers, counts in hist_data:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=bin_centers,\n",
    "        y=counts,\n",
    "        name=f'Class {cls}',\n",
    "        opacity=0.6\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=f'Histogram of Router V1 Client LB by Class',\n",
    "    xaxis_title='Logit Value',\n",
    "    yaxis_title='Frequency',\n",
    "    barmode='overlay',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a702607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "bins = 30\n",
    "target_filter =  [1,3,5] # list(range(10)) #  [1,3,5]\n",
    "classes = np.unique(h2_targets[27])\n",
    "logits = np.array(h2_clients_routers[27][2])\n",
    "targets = h2_targets[4]\n",
    "\n",
    "\n",
    "if not isinstance(target_filter, (list, np.ndarray)):\n",
    "    target_filter = [target_filter]\n",
    "\n",
    "hist_data = []\n",
    "bin_edges = None\n",
    "\n",
    "for cls in classes:\n",
    "    if cls not in target_filter:\n",
    "        continue\n",
    "\n",
    "    mask = targets == cls\n",
    "    class_logits = logits[mask]\n",
    "    counts, edges = np.histogram(class_logits, bins=bins)\n",
    "\n",
    "    if bin_edges is None:\n",
    "        bin_edges = edges\n",
    "\n",
    "    bin_centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "    hist_data.append((cls, bin_centers, counts))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for cls, bin_centers, counts in hist_data:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=bin_centers,\n",
    "        y=counts,\n",
    "        name=f'Class {cls}',\n",
    "        opacity=0.6\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    # title=f'Histogram of Router V1 Client LB by Class',\n",
    "    xaxis_title='Logit Value',\n",
    "    yaxis_title='Frequency',\n",
    "    barmode='overlay',\n",
    "    template='plotly_white',\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "bins = 30\n",
    "target_filter = list(range(10))  # Filter specific classes\n",
    "classes = np.unique(h1_targets[27])  # Available classes\n",
    "logits = np.array(h1_clients_routers[27][0])  # Logits\n",
    "targets = np.array(h1_targets[27])  # Ground truth labels\n",
    "preds = np.array(h1_clients_preds[27][0])  # Client predictions\n",
    "\n",
    "if not isinstance(target_filter, (list, np.ndarray)):\n",
    "    target_filter = [target_filter]\n",
    "\n",
    "hist_data_correct = []\n",
    "hist_data_incorrect = []\n",
    "bin_edges = None\n",
    "\n",
    "for cls in classes:\n",
    "    if cls not in target_filter:\n",
    "        continue\n",
    "\n",
    "    mask = targets == cls\n",
    "    class_logits = logits[mask]\n",
    "    class_preds = preds[mask]\n",
    "    class_targets = targets[mask]\n",
    "\n",
    "    # Correct and incorrect masks\n",
    "    correct_mask = class_preds == class_targets\n",
    "    incorrect_mask = ~correct_mask\n",
    "\n",
    "    # Histogram for correct\n",
    "    counts_correct, edges = np.histogram(class_logits[correct_mask], bins=bins)\n",
    "    if bin_edges is None:\n",
    "        bin_edges = edges\n",
    "    bin_centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "    hist_data_correct.append((cls, bin_centers, counts_correct))\n",
    "\n",
    "    # Histogram for incorrect\n",
    "    counts_incorrect, _ = np.histogram(class_logits[incorrect_mask], bins=edges)\n",
    "    hist_data_incorrect.append((cls, bin_centers, counts_incorrect))\n",
    "\n",
    "# Plotting\n",
    "fig = go.Figure()\n",
    "\n",
    "for cls, bin_centers, counts in hist_data_correct:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=bin_centers,\n",
    "        y=counts,\n",
    "        name=f'Class {cls} (Correct)',\n",
    "        opacity=0.6\n",
    "    ))\n",
    "\n",
    "for cls, bin_centers, counts in hist_data_incorrect:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=bin_centers,\n",
    "        y=counts,\n",
    "        name=f'Class {cls} (Incorrect)',\n",
    "        opacity=0.6,\n",
    "        marker=dict(pattern_shape=\"/\")\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Histogram of Router V1 Client LB by Class (Correct vs Incorrect)',\n",
    "    xaxis_title='Logit Value',\n",
    "    yaxis_title='Frequency',\n",
    "    barmode='overlay',\n",
    "    template='plotly_white',\n",
    "    legend_title='Legend'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1df0cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "bins = 30\n",
    "target_filter =  list(range(10)) # [1, 3, 5] \n",
    "classes = np.unique(h1_targets[13])\n",
    "logits = np.array(h1_clients_routers[13][3])\n",
    "targets = h1_targets[4]\n",
    "\n",
    "if not isinstance(target_filter, (list, np.ndarray)):\n",
    "    target_filter = [target_filter]\n",
    "\n",
    "hist_data = []\n",
    "bin_edges = None\n",
    "class_means = {}\n",
    "class_max_heights = {}\n",
    "\n",
    "for cls in classes:\n",
    "    if cls not in target_filter:\n",
    "        continue\n",
    "\n",
    "    mask = targets == cls\n",
    "    class_logits = logits[mask]\n",
    "    counts, edges = np.histogram(class_logits, bins=bins)\n",
    "\n",
    "    if bin_edges is None:\n",
    "        bin_edges = edges\n",
    "\n",
    "    bin_centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "    hist_data.append((cls, bin_centers, counts))\n",
    "\n",
    "    # Store mean and max count for placing the line and annotation\n",
    "    class_means[cls] = np.mean(class_logits)\n",
    "    class_max_heights[cls] = max(counts)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot histogram bars\n",
    "for cls, bin_centers, counts in hist_data:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=bin_centers,\n",
    "        y=counts,\n",
    "        name=f'Class {cls}',\n",
    "        opacity=0.6\n",
    "    ))\n",
    "\n",
    "# Add vertical mean lines and annotations\n",
    "for cls in class_means:\n",
    "    mean_val = class_means[cls]\n",
    "    max_y = class_max_heights[cls]\n",
    "\n",
    "    # Mean line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[mean_val, mean_val],\n",
    "        y=[0, max_y],\n",
    "        mode='lines',\n",
    "        line=dict(dash='dash', color='black'),\n",
    "        name=f'Mean Class {cls}',\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    # Mean value label near x-axis\n",
    "    fig.add_annotation(\n",
    "        x=mean_val,\n",
    "        y=-0.01,  # Slightly below x-axis\n",
    "        xref='x',\n",
    "        yref='paper',\n",
    "        text=f\"{mean_val:.2f}\",\n",
    "        showarrow=False,\n",
    "        xanchor='center',\n",
    "        yanchor='top',\n",
    "        font=dict(size=10, color='black')\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Histogram of Router V1 Client RB by Class (with Mean Lines)',\n",
    "    xaxis_title='Logit Value',\n",
    "    yaxis_title='Frequency',\n",
    "    barmode='overlay',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "bins = 30\n",
    "target_filter = list(range(10)) # \n",
    "classes = np.unique(h1_targets[4])\n",
    "logits = []\n",
    "targets = []\n",
    "for i in h1_clients_routers[4].keys():\n",
    "    logits += list(h1_clients_routers[4][i])\n",
    "    targets += h1_targets[4]\n",
    "logits  = np.array(logits)   \n",
    "targets  = np.array(targets)                       \n",
    "\n",
    "if not isinstance(target_filter, (list, np.ndarray)):\n",
    "    target_filter = [target_filter]\n",
    "\n",
    "hist_data = []\n",
    "bin_edges = None\n",
    "\n",
    "for cls in classes:\n",
    "    if cls not in target_filter:\n",
    "        continue\n",
    "\n",
    "    mask = targets == cls\n",
    "    class_logits = logits[mask]\n",
    "    counts, edges = np.histogram(class_logits, bins=bins)\n",
    "\n",
    "    if bin_edges is None:\n",
    "        bin_edges = edges\n",
    "\n",
    "    bin_centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "    hist_data.append((cls, bin_centers, counts))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for cls, bin_centers, counts in hist_data:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=bin_centers,\n",
    "        y=counts,\n",
    "        name=f'Class {cls}',\n",
    "        opacity=0.6\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Histogram of Router V1 by Class',\n",
    "    xaxis_title='Logit Value',\n",
    "    yaxis_title='Frequency',\n",
    "    barmode='overlay',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4795a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "client_mapping = {\n",
    "    0: \"left top (LT)\",\n",
    "    1: \"right top (RT)\",\n",
    "    2: \"left bottom (LB)\",\n",
    "    3: \"right bottom (RB)\"\n",
    "}\n",
    "\n",
    "def plot_accuracy_vs_coverage(coverage, hybrid_accuracy):\n",
    "    thresholds = sorted(coverage.keys())\n",
    "    clients = sorted(hybrid_accuracy.keys())\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    best_acc_at_cov1 = []\n",
    "\n",
    "    for client_id in clients:\n",
    "        covs = np.array([coverage[t][client_id] for t in thresholds])\n",
    "        accs = np.array([hybrid_accuracy[client_id][t] for t in thresholds])\n",
    "        flipped = (1-covs)\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=flipped,\n",
    "                y=accs,\n",
    "                mode='lines+markers',\n",
    "                name=f'Client {client_mapping[client_id]}'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        mask = np.isclose(covs, 1.0)\n",
    "        if np.any(mask):\n",
    "            best_acc_at_cov1.append(accs[mask][0])\n",
    "\n",
    "    if best_acc_at_cov1:\n",
    "        max_acc = max(best_acc_at_cov1)\n",
    "        fig.add_hline(\n",
    "            y=max_acc,\n",
    "            line_dash=\"dash\",\n",
    "            line_color=\"red\",\n",
    "            annotation_text=f\"Best local accuracy: {max_acc:.3f}\",\n",
    "            annotation_position=\"top right\"\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Hybrid Accuracy vs. Local Coverage per Client',\n",
    "        xaxis=dict(\n",
    "            title='Remote Coverage (Fraction of samples processed by the Cloud)',\n",
    "            range=[0, 1],\n",
    "            autorange=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Hybrid Accuracy',\n",
    "            range=[0, 1],\n",
    "            autorange=False\n",
    "        ),\n",
    "        legend_title='Clients',\n",
    "        width=800,\n",
    "        height=500,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e647c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "bins = 30\n",
    "\n",
    "\n",
    "seed = 13  \n",
    "client_id = 0\n",
    "logits = np.array(h2_clients_routers[seed][client_id])\n",
    "preds = np.array(h2_clients_preds[seed][client_id])\n",
    "targets = np.array(h2_targets[seed])[:len(preds)]\n",
    "\n",
    "correct_mask = preds == targets\n",
    "incorrect_mask = ~correct_mask\n",
    "\n",
    "correct_logits = logits[correct_mask]\n",
    "incorrect_logits = logits[incorrect_mask]\n",
    "\n",
    "\n",
    "c_counts, bin_edges = np.histogram(correct_logits, bins=bins)\n",
    "ic_counts, _ = np.histogram(incorrect_logits, bins=bin_edges)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=bin_centers,\n",
    "    y=c_counts,\n",
    "    name='Correct',\n",
    "    opacity=0.7,\n",
    "    marker_color='green'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=bin_centers,\n",
    "    y=ic_counts,\n",
    "    name='Incorrect',\n",
    "    opacity=0.7,\n",
    "    marker_color='crimson'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Router Logits Histogram for Client {client_id} (Seed {seed})',\n",
    "    xaxis_title='Router Logit',\n",
    "    yaxis_title='Frequency',\n",
    "    barmode='overlay',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b2640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "bins = 30\n",
    "\n",
    "\n",
    "seed = 13  \n",
    "client_id = 1\n",
    "logits = np.array(h2_clients_routers[seed][client_id])\n",
    "preds = np.array(h2_clients_preds[seed][client_id])\n",
    "targets = np.array(h2_targets[seed])[:len(preds)]\n",
    "\n",
    "correct_mask = preds == targets\n",
    "incorrect_mask = ~correct_mask\n",
    "\n",
    "correct_logits = logits[correct_mask]\n",
    "incorrect_logits = logits[incorrect_mask]\n",
    "\n",
    "\n",
    "c_counts, bin_edges = np.histogram(correct_logits, bins=bins)\n",
    "ic_counts, _ = np.histogram(incorrect_logits, bins=bin_edges)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=bin_centers,\n",
    "    y=c_counts,\n",
    "    name='Correct',\n",
    "    opacity=0.7,\n",
    "    marker_color='green'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=bin_centers,\n",
    "    y=ic_counts,\n",
    "    name='Incorrect',\n",
    "    opacity=0.7,\n",
    "    marker_color='crimson'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'Router Logits Histogram for Client {client_id} (Seed {seed})',\n",
    "    xaxis_title='Router Logit',\n",
    "    yaxis_title='Frequency',\n",
    "    barmode='overlay',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb2b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_hybrid_accuracy(logits, preds, server, targets, thresholds): \n",
    "    hybrid_accuracy = {}\n",
    "    coverages = {} \n",
    "    for threshold in thresholds:\n",
    "        hybrid_accuracy[np.float64(round(threshold, 4))] = {}\n",
    "        coverages[np.float64(round(threshold, 4))] = {}\n",
    "        for key in preds.keys():\n",
    "            cloud_routing_decision = np.array(logits[0])>threshold\n",
    "            local_routing_decision = ~cloud_routing_decision\n",
    "            coverage = sum(cloud_routing_decision)/len(targets)\n",
    "            hybrid = sum((preds[key] == targets)*local_routing_decision) + sum((server == targets)*cloud_routing_decision)\n",
    "            hybrid = hybrid/len(targets)\n",
    "            coverages[np.float64(round(threshold, 4))][key] = coverage\n",
    "            hybrid_accuracy[np.float64(round(threshold, 4))][key] = hybrid\n",
    "    return hybrid_accuracy, coverages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27800d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 13\n",
    "thresholds = np.linspace(1, 0, 100) \n",
    "logits = h1_clients_routers[seed]\n",
    "preds = h1_clients_preds[seed]\n",
    "server =  h1_server_preds[seed]\n",
    "targets = np.array(h1_targets[seed])\n",
    "\n",
    "hybrid_accuracy, coverages = calculate_hybrid_accuracy(logits, preds, server, targets, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ea5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientmapper = ['LT', 'RT', 'LB', 'RB']\n",
    "clients = list(preds.keys())\n",
    "sorted_thresholds = sorted(hybrid_accuracy.keys())\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for client in clients:\n",
    "    coverage_vals = [coverages[t][client] for t in sorted_thresholds]\n",
    "    accuracies = [hybrid_accuracy[t][client] for t in sorted_thresholds]\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=coverage_vals, \n",
    "        y=accuracies,\n",
    "        mode='lines+markers',\n",
    "        name=f'Client {clientmapper[client]}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    #title='Hybrid V1 - Hybrid Accuracy vs Coverage by Clients',\n",
    "    xaxis_title='Coverage',\n",
    "    yaxis_title='Hybrid Accuracy',\n",
    "    xaxis=dict(range=[0, 1]),\n",
    "    yaxis=dict(range=[0, 1]),\n",
    "    template='plotly_white',\n",
    "    legend_title=\"Clients\",\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "max_local = max(local_mean)\n",
    "fig.add_hline(\n",
    "    y=max_local,\n",
    "    line=dict(color='Red', dash='dash'),\n",
    "    annotation_text=f'Max Local-Only Accuracy = {max_local:.3f}',\n",
    "    annotation_position='top right'\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 4\n",
    "thresholds = np.linspace(1, 0, 100) \n",
    "logits = h2_clients_routers[seed]\n",
    "preds = h2_clients_preds[seed]\n",
    "server =  h2_server_preds[seed]\n",
    "targets = np.array(h2_targets[seed])\n",
    "hybrid_accuracy, coverages = calculate_hybrid_accuracy(logits, preds, server, targets, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b05e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientmapper = ['LT', 'RT', 'LB', 'RB']\n",
    "clients = list(preds.keys())\n",
    "sorted_thresholds = sorted(hybrid_accuracy.keys())\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for client in clients:\n",
    "    coverage_vals = [coverages[t][client] for t in sorted_thresholds]\n",
    "    accuracies = [hybrid_accuracy[t][client] for t in sorted_thresholds]\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=coverage_vals, \n",
    "        y=accuracies,\n",
    "        mode='lines+markers',\n",
    "        name=f'Client {clientmapper[client]}'\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    #title='Hybrid V2 - Hybrid Accuracy vs Coverage by Clients',\n",
    "    xaxis_title='Coverage',\n",
    "    yaxis_title='Hybrid Accuracy',\n",
    "    xaxis=dict(range=[0, 1]),\n",
    "    yaxis=dict(range=[0, 1]),\n",
    "    template='plotly_white',\n",
    "    legend_title=\"Clients\"\n",
    ")\n",
    "\n",
    "max_local = max(local_mean)\n",
    "fig.add_hline(\n",
    "    y=max_local,\n",
    "    line=dict(color='Red', dash='dash'),\n",
    "    annotation_text=f'Max Local-Only Accuracy = {max_local:.3f}',\n",
    "    annotation_position='top right'\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a024e7",
   "metadata": {},
   "source": [
    "plot_accuracy_vs_coverage(_coverage, _hybrid_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
